{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "““UNIKEY_COMP5046_Ass1.ipynb”的副本”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnnyPeng123/NLP-USYD/blob/master/JPEN6856_COMP5046_Ass1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHoy6KpQDfZ",
        "colab_type": "text"
      },
      "source": [
        "# COMP5046 Assignment 1\n",
        "*To skip the model training parts and save your time and, please only run cells with \"Run This Cell\" sign. Please do not run cells without this sign, unless you would like to play with codes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34DVNKgqQY21",
        "colab_type": "text"
      },
      "source": [
        "# 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cWUxAQrGlq6",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7C4snIcNl22",
        "colab_type": "code",
        "outputId": "7a96d2e6-77b9-43ce-843f-bdb588dd7775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "####################################\n",
        "###### Run This Cell #########\n",
        "####################################\n",
        "\n",
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "!pip install unidecode\n",
        "!pip3 install lemminflect\n",
        "!pip install spacy\n",
        "import unidecode\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1vF3FqgBC1Y-RPefeVmY8zetdZG1jmHzT'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_train.csv')\n",
        "\n",
        "id = '1XhaV8YMuQeSwozQww8PeyiWMJfia13G6'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_test.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"imdb_train.csv\")\n",
        "df_test = pd.read_csv(\"imdb_test.csv\")\n",
        "\n",
        "reviews_train = df_train['review'].tolist()\n",
        "sentiments_train = df_train['sentiment'].tolist()\n",
        "reviews_test = df_test['review'].tolist()\n",
        "sentiments_test = df_test['sentiment'].tolist()\n",
        "\n",
        "reviews_train_original = df_train['review'].tolist()\n",
        "reviews_test_original = df_test['review'].tolist()\n",
        "\n",
        "print(\"Training set number:\",len(reviews_train))\n",
        "print(\"Testing set number:\",len(reviews_test))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n",
            "Collecting lemminflect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/c5/62e8dd0b6cbfea212cf55a2338838d85a819dbda9462ba53a415dcf19b86/lemminflect-0.2.1-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lemminflect) (1.18.2)\n",
            "Installing collected packages: lemminflect\n",
            "Successfully installed lemminflect-0.2.1\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.38.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Training set number: 25000\n",
            "Testing set number: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9gBSgBCQh24",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RdKI8E2KRwe",
        "colab_type": "text"
      },
      "source": [
        "Here are the processing steps that we'll take to clean up our data:\n",
        ">\n",
        "1. Case folding - Convert all the characters to lower-case.\n",
        "  * Reason: Even though Upper-case and lower-case might change the meaning of a sentence in some situation, but the overall sentiment of the reviews are unlikely to be impacted by this, and by doing this we can reduce the sparseness of our data.\n",
        "\n",
        "  * Codes: words.lower()\n",
        "\n",
        "1. Expand Contractions.\n",
        "  * Reason: Reduce sparseness of our data. It is not ideal to treat words like \"you're\" as a separate single word in our vocab.\n",
        "\n",
        "  * Codes: expand_contractions()  \n",
        "\n",
        "2. Get rid of periods and extraneous punctuation.\n",
        "  * Reason: Punctuations cannot indicate whether a review is positive or negative, rather, it indicates the magnitudes of the sentiment. Thus, it's not useful for our purpose given we are not trying to predictive the magnitudes, hence we will get rid of them.  \n",
        "\n",
        "  * Codes: remove_punctuation_re()\n",
        "\n",
        "3. Tokenisation - Convert reviews to words level.\n",
        "  * Reason: We will need to train and use embeddings at the word level, also word-level data transformation will happen in the next step.\n",
        "  \n",
        "  * Codes: word_tokenize()\n",
        "4. Normalization - Remove accents for all the words in our texts.\n",
        "  * Reason: Accents do not contribute to the sentiment of a movie review, and by doing this we can reduce the sparseness of our data.\n",
        "\n",
        "  * Codes: unidecode.unidecode()\n",
        "5. Remove misspell words and made-up words\n",
        "  * Reason: These words are likely to be very infrequent in our data, and hence it is unlikely to get a meaningful embedding out of it, might as well remove them to reduce dataset size and speed up the training process.\n",
        "\n",
        "  * Codes: words in english_words\n",
        "\n",
        "6. Remove Numbers.\n",
        "  * Reason: Like punctuations, numbers carry quantitative meanings, which contribute little to predicting the sentiment of the reviews. \n",
        "  \n",
        "  * Codes: word.isalpha()\n",
        "\n",
        "6. Remove words with single characters.\n",
        "  * Reason: After the punctuations got removed from our text, some single characters will not make sense anymore. For example, \"Jack's apple\" will become \"jack s apple\", even though that s can still provide some dependency information, however, I do not think that can change the sentiment of the review. Note that there are three exceptions, \"a\",\"i\" will be kept, and \"u\" will be converted to \"you\". \n",
        "  \n",
        "  * Codes: word not in single_words\n",
        "\n",
        "7. POS tagging.\n",
        "  * Reason: since we will be performing lemmatization in the next step, we are required to perform POS tagging beforehand to do lemmatization properly.\n",
        "\n",
        "  * Codes: nlp(' '.join(review_tmp))  \n",
        "\n",
        "8. Lemmatization\n",
        "  * Reason: Lemmatiztion helps to normalize our words by grouping the same words with different forms together, and hence reduce sparseness in our data, which would be beneficial for both training embeddings and sentiment analysis.\n",
        "\n",
        "  * Codes: w._.lemma()\n",
        "\n",
        "Note that these steps have to happen in order, otherwise the final results might be different. For example, we will be making mistake if we remove punctuations before expanding contractions, that is because after we remove punctuations \"you're\" will become \"youre\", which is not in our contractions dictionary.  \n",
        "\n",
        "Please also note that I am not happy with the accuracy of the lemmatization package from nltk, so I have installed some external libraries to perform the lemmatization task instead. These libraries include: spacy, lemminflect \n",
        "\n",
        "The english_words dictionary used in this code are from the Github below:\n",
        "https://github.com/dwyl/english-words\n",
        "\n",
        "I find the English dictionary from nltk very out-of-date. For example, the English dictionary from nltk does not even have the word \"enjoyed\" in it. so I used the one above instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsIXp9W0TBez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "id = '1o2k7nw9oYWMAsgKEFBCAeaMIWlCqBB8m'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('words_alpha.txt')\n",
        "\n",
        "def load_words():\n",
        "    with open('words_alpha.txt') as word_file:\n",
        "        valid_words = set(word_file.read().split())\n",
        "\n",
        "    return valid_words\n",
        "\n",
        "english_words = load_words()\n",
        "\n",
        "import re\n",
        "contractions_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
        "                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
        "                    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
        "                    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \n",
        "                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
        "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
        "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n",
        "                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
        "                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n",
        "                    \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
        "                    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
        "                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \n",
        "                    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \n",
        "                    \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
        "                    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n",
        "                    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \n",
        "                    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \n",
        "                    \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n",
        "                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
        "                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "def expand_contractions(s, contractions_dict=contractions_dict):\n",
        "    def replace(match):\n",
        "        return contractions_dict[match.group(0)]\n",
        "    s = re.sub(\"\\'\",\"'\",s)\n",
        "    return contractions_re.sub(replace, s)\n",
        "\n",
        "def remove_punctuation_re(x):\n",
        "    x = re.sub('<br />',' ',x)\n",
        "    x = re.sub(r'[^\\w\\s]',' ',x)\n",
        "    x = re.sub(' u ',' you',x)\n",
        "    return x\n",
        "\n",
        "def remove_punctuation_re2(x):\n",
        "    x = re.sub(r'[^\\w\\s]','',x)\n",
        "    return x\n",
        "\n",
        "single_words = ['b', 'c', 'd', 'e', 'f', 'g',\n",
        "         'h', 'j', 'k', 'l', 'm', 'n',\n",
        "         'o', 'p', 'q', 'r', 's', 't', 'u',\n",
        "         'v', 'w', 'x', 'y', 'z']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lMbD7zYZgLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import lemminflect\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def preprocess(data):\n",
        "  for i in range(len(data)):\n",
        "    review_tmp = []\n",
        "    review_final = []\n",
        "    data_temp = remove_punctuation_re(expand_contractions(data[i].lower()))\n",
        "    for word in word_tokenize(data_temp):\n",
        "      word_temp = unidecode.unidecode(word)\n",
        "      if word_temp.isalpha() and word_temp in english_words and word_temp not in single_words:\n",
        "        review_tmp.append(word_temp)\n",
        "    review_tmp1 = nlp(' '.join(review_tmp))\n",
        "    for w in review_tmp1:\n",
        "      review_final.append(remove_punctuation_re2(str(w._.lemma())))\n",
        "    data[i] = ' '.join(review_final)\n",
        "  return data\n",
        "\n",
        "reviews_train = preprocess(reviews_train)\n",
        "reviews_test = preprocess(reviews_test)\n",
        "\n",
        "# create a list that contains the all the words from both training and test dataset\n",
        "reviews = reviews_test + reviews_train\n",
        "all_text = ' '.join([w for w in reviews])\n",
        "all_words = all_text.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9l9Wmx9XcMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the pre-processed data, preventing from re-running the pre-process steps.\n",
        "with open(\"/content/drive/My Drive/reviews_test.txt\", \"w\") as f:\n",
        "    for s in reviews_test:\n",
        "        f.write(str(s) +\"\\n\")\n",
        "\n",
        "with open(\"/content/drive/My Drive/reviews_train.txt\", \"w\") as f:\n",
        "    for s in reviews_train:\n",
        "        f.write(str(s) +\"\\n\")\n",
        "\n",
        "with open(\"/content/drive/My Drive/all_words.txt\", \"w\") as f:\n",
        "    for s in all_words:\n",
        "        f.write(str(s) +\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUG7uDcu2ylv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_test_original = reviews_test\n",
        "reviews_train_original = reviews_train\n",
        "all_words_original = all_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RABiaNK2XtX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "# Load the pre-processed data.\n",
        "reviews_test = []\n",
        "reviews_train = []\n",
        "all_words = []\n",
        "\n",
        "id = '1-8-7FqqcfhssoBtygvUk_JLUEDX_OcEn'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('reviews_test.txt')\n",
        "\n",
        "id = '1-8HCFH6YMo9ODwcZid5W2AauBFXjCPyI'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('reviews_train.txt')\n",
        "\n",
        "id = '1-8TuOnFLSxdpQv7qG8lyQORAJLQuLXDG'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('all_words.txt')\n",
        "\n",
        "with open(\"reviews_test.txt\", \"r\") as f:\n",
        "  for line in f:\n",
        "    reviews_test.append(line.strip())\n",
        "\n",
        "with open(\"reviews_train.txt\", \"r\") as f:\n",
        "  for line in f:\n",
        "    reviews_train.append(line.strip())\n",
        "\n",
        "with open(\"all_words.txt\", \"r\") as f:\n",
        "  for line in f:\n",
        "    all_words.append(line.strip())\n",
        "\n",
        "reviews = reviews_train + reviews_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-Z7nuS5XQwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "from collections import Counter\n",
        "import numpy as np \n",
        "\n",
        "## Build a dictionary that maps words to integers\n",
        "counts = Counter(all_words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab)}\n",
        "\n",
        "## use the dict to tokenize each words in reviews.split()\n",
        "## store the tokenized reviews in reviews_ints_train & reviews_ints_test\n",
        "reviews_ints_train = []\n",
        "for review in reviews_train:\n",
        "    reviews_ints_train.append([vocab_to_int[word] for word in review.split()])\n",
        "\n",
        "reviews_ints_test = []\n",
        "for review in reviews_test:\n",
        "    reviews_ints_test.append([vocab_to_int[word] for word in review.split()])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOR_f6O7zDpE",
        "colab_type": "code",
        "outputId": "cf4cf765-2697-46b8-ce21-022a10b20daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(all_words))\n",
        "print(len(vocab))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11385282\n",
            "43054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsMYZNV_hl_K",
        "colab_type": "code",
        "outputId": "81776f87-42e8-417d-c7d8-934ece0439c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Manual spot check\n",
        "print(reviews_test_original[7])\n",
        "print(reviews_test[7])\n",
        "print(sentiments_test_int[7])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I think the film makes a subtile reference to rouge of Kieslowski, as the whole atmosphere gives me a feeling of red. It seems to be that a lot of the backgrounds contain red, think of the tea-room f.e. I also think this is one of the greatest movies of the last years.\n",
            "i think the film make a subtile reference to rouge of as the whole atmosphere give me a feeling of red it seem to be that a lot of the background contain red think of the tea room i also think this be one of the great movie of the last year\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOzawwkPVzTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "# Define efficient one-encoding function for Tensors\n",
        "def to_one_hot(y, n_dims=None):\n",
        "    \"\"\" Take integer y (tensor or variable) with n dims and convert it to 1-hot representation with n+1 dims. \"\"\"\n",
        "    y_tensor = y.data if isinstance(y, Variable) else y\n",
        "    y_tensor = y_tensor.type(torch.LongTensor).view(-1, 1)\n",
        "    n_dims = n_dims if n_dims is not None else int(torch.max(y_tensor)) + 1\n",
        "    y_one_hot = torch.zeros(y_tensor.size()[0], n_dims).scatter_(1, y_tensor, 1)\n",
        "    y_one_hot = y_one_hot.view(*y.shape, -1)\n",
        "    return Variable(y_one_hot) if isinstance(y, Variable) else y_one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIu_lkJwQ55g",
        "colab_type": "text"
      },
      "source": [
        "# 2 - Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daDvAftceIvr",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbzm-NWBTmM-",
        "colab_type": "text"
      },
      "source": [
        "We will be implementing the Skip-Gram model, which is a neural network model which use the target words to predicts its context words. All the words in our text will be the target words, and the words around each target words will be the context words.\n",
        "\n",
        "Once the model is trained, the hidden layers will be the word embeddings that we can use to train character embedding and perform sentiment analysis. \n",
        "\n",
        "The reasons that we chose Skip-Gram over CBOW is shown below:\n",
        ">\n",
        "* Skip-Gram model is better for infrequent words, although it is slower to train compared to the CBOW approach.\n",
        "  * Skip-Gram is a one-to-one model, which means that a target word is responsible to predict/explain one context word, that means when the loss was generated from the backprop, one single target word's embedding will absorb all the loss and update correspondingly. \n",
        "  \n",
        "    Whereas CBOW uses multiple context words to predict the target words, so each context words will be responsible to explain parts of the target word, which also means that each of the word embeddings will not get updated as much (as in the Skip-Gram model) during the training process.  \n",
        "\n",
        "    For frequent words, both CBOW and Skip-Gram should be fine as they appear a lot in our training dataset, and hence their word embedding got update more often.   \n",
        "    \n",
        "    However, for infrequent words, their embeddings are more likely to be under-trained in the CBOW model as the update magnitude is relatively smaller in CBOW.  \n",
        "\n",
        "    The original word2vec paper from Google also endorsed this idea:\n",
        "  https://code.google.com/archive/p/word2vec/\n",
        "  \n",
        "    (Under the \"Performance\" sub-title, search for \"performance\" to see it)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXgFpxIgl-_G",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1. Data Preprocessing for Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJrVHGYSmYMg",
        "colab_type": "text"
      },
      "source": [
        "Following are the data preprocessing done for training the word embeddings:\n",
        "\n",
        ">\n",
        "1. Sub-sampling frequent words\n",
        "  * This is a common technique used in NLP to create a more balanced training dataset, where we discard words in our training dataset based on their frequency in our data. More frequent words are more likely to get discarded. That way our training process will not be dominant by frequent but meanless stop words such as \"the\", \"is\", \"are\".    \n",
        "\n",
        "     One benefit of sub-sample frequent words is that, it does not remove all the stop words, rather, it merely reduces the frequency of the stop words in our training dataset. This is a desired feature as some of the stop words can change the sentiment of the sentence. Take \"This movie is not good.\" as an example, if we remove all the stop words, the sentence will become \"movie good.\", which has a sentiment that is opposite to the original sentence.\n",
        "\n",
        "     Other benefits of sub-sample frequent words including improving both accuracy and speed for large data sets, which endorsed by the original Word2Vec paper by Google:\n",
        "\n",
        "     https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "    (Under the \"Performance\" sub-title, search for \"performance\" to see it)\n",
        "\n",
        "\n",
        "2. Break the reviews into target words and context words.\n",
        "  * Detailed process is shown in the code, which creates the training dataset for the Skip-Gram model.  \n",
        "\n",
        "3. One-hot Encoding.\n",
        "  * One-hot encoding is applied to convert the target words into a spare vector that feeds into the Skip-Gram model. Note that, due to the RAM limit on Colab, this is done by batches when training the Skip-Gram model.\n",
        "   \n",
        "Note that I did not implement the \"Negative Sampling\" or \"Hierarchical Softmax\" techniques due to time constraints on this assignment, if I have more time I would definitely give them a go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXvcCdxu5x9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(88)\n",
        "\n",
        "reviews_subsample = []\n",
        "for review in reviews:\n",
        "  review_temp = []\n",
        "  for word in review.split():\n",
        "    frac = counts[word]/len(all_words)\n",
        "    prob = (np.sqrt(frac/0.001) + 1) * (0.001/frac)\n",
        "    \n",
        "    if np.random.random() < prob:\n",
        "        review_temp.append(word)\n",
        "  \n",
        "  reviews_subsample.append(' '.join([w for w in review_temp]))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTkGebr2oEIU",
        "colab_type": "code",
        "outputId": "f0c7ed0a-a16f-4b8c-b050-48076b160a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Making window size 5 skip-gram\n",
        "skip_grams_target = []\n",
        "skip_grams_context = []\n",
        "vocab_size = len(vocab_to_int)\n",
        "window_size = 5\n",
        "\n",
        "for j in range(len(reviews_subsample)):\n",
        "  words = word_tokenize(reviews_subsample[j])\n",
        "  for i in range(len(words)):\n",
        "    target = vocab_to_int[words[i]]\n",
        "    context_temp = []\n",
        "    \n",
        "    if i >= window_size and i <= (len(words) - window_size):   \n",
        "      for word in words[i - window_size:i]:\n",
        "          context_temp.append(vocab_to_int[word])\n",
        "      for word in words[i+1:i + window_size + 1]:\n",
        "          context_temp.append(vocab_to_int[word])\n",
        "    \n",
        "    if i < window_size:\n",
        "      if i > 0:\n",
        "       for word in words[0:i]:\n",
        "           context_temp.append(vocab_to_int[word])\n",
        "      for word in words[i+1:i + window_size + 1]:\n",
        "          context_temp.append(vocab_to_int[word])\n",
        "\n",
        "    if i > (len(words) - window_size):\n",
        "      for word in words[i - window_size:i]:\n",
        "          context_temp.append(vocab_to_int[word])\n",
        "      if i != len(words)-1:\n",
        "       for word in words[i+1:len(words)]:\n",
        "           context_temp.append(vocab_to_int[word])\n",
        "\n",
        "    context = context_temp\n",
        "\n",
        "    # skipgrams - (target, context[0]), (target, context[1])..\n",
        "    for w in context:\n",
        "          skip_grams_target.append(target)\n",
        "          skip_grams_context.append(w)    \n",
        "\n",
        "print(len(skip_grams_target))\n",
        "print(len(skip_grams_context))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78945061\n",
            "78945061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weoNbf62wLiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Batches\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "batch_size = 1000\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(np.array(skip_grams_target)), torch.from_numpy(np.array(skip_grams_context)))\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers = 4, pin_memory=True, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhAgWf_AmbZ8",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.2. Build Word Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ8rU7JbiBVS",
        "colab_type": "text"
      },
      "source": [
        "Here are justifications for the hyperparameter choices:\n",
        ">\n",
        "1. Number of Epoch = 1\n",
        "  * Reason: Our training dataset is too big, even 1 epoch will takes at least a few hours to train (also depends on other hyperparameters). Given the Colab's runtime will be reset after every 12 hours or when the laptop is not active, if I set the number epoch to be greater than 1, it's very likely the Colab runtime will be reset before the training process finish. At that point, I will have to re-train everything again. So even though I believe more epoch here might gives a more accurate results, but I still set it to be 1 here. \n",
        "\n",
        "    In addition, the loss is pretty much converged at end of the first epoch, so marginal benefit from additional epoch would be minimal.   \n",
        "2. Batch Size = 1000\n",
        "  * Reason: Given the large dataset that we are working with, I tried to set the batch size as high as possible to speed up the training process. Due to the RAM constraints on the CPU in Colab, 1000 batch size is roughtly the highest batch size I can set.  \n",
        "\n",
        "3. Window Size = 5\n",
        "  * Reason: Even though the orignal paper word2vec paper from google recommended window size of 10 for skip-gram model, however it will makes the training dataset significantly bigger than window size of 5. Due to the time constraints on this assignmetn, and the runtime & RAM limits on Colab, I decided to go with the window size of 5.  \n",
        "  \n",
        "4. Probability threshold for the sub-sampling frequent words = 1e-3\n",
        "  * Reason: The original word2vec paper by Google recommended 1e-3 to 1e-5 for this hyperparameter. After trying out both 1e-3 and 1e-5, training with 1e-3 lead to a much lower losses compare to training with 1e-5. That might because the probability threshold 1e-5 is too low, which causing too many words being  removed, and thus destoryed the relevance between target words and context words.    \n",
        "  \n",
        "5. Learning Rate = 0.0001\n",
        "  * Reason: After multiple trial and errors, this learning rate = 0.0001 seems to give the lowest and the most stable losses.\n",
        "\n",
        "6. Embedding Size = 100\n",
        "  * Reason: After trying out different embedding sizes (50, 100, 300), I found that there is no signifcant difference in losses between embedding size of 100 and 300, whlist training with embedding size = 100 is signficantly faster. However, dropping the embedding size from 100 to 50 signifcantly increased the losses, which is not desired. Thus, the embedding size was set at 100.  \n",
        "\n",
        "Note that, some of the reasoning above are based on the training losses and trial & errors. Even though I forgot to keep a track of all the results (otherwise I could have visualize them here), I hope explain them as text would makes sense to you. \n",
        "\n",
        "In addition, even though I understand that the losses from training the word embedding may not indicates its effectiveness in the end-application (which is sentiment analysis in this case). However, due to the time constraints, I am unable to run the end-to-end process (training word embedding + training character embedding + sentiment analysis) multiple times to find the best hyperparameter for training the word embedding.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVPuwWgvNjOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#hyperparameters\n",
        "learning_rate = 0.0001\n",
        "embedding_size = 100\n",
        "voc_size = len(vocab_to_int)\n",
        "\n",
        "class SkipGram(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SkipGram, self).__init__()\n",
        "        self.linear1 = nn.Linear(voc_size, embedding_size,bias=False)\n",
        "        self.linear2 = nn.Linear(embedding_size, voc_size,bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.linear1(x)\n",
        "        out = self.linear2(hidden)\n",
        "        return out\n",
        "\n",
        "skip_gram_model = SkipGram().to(device)\n",
        "criterion = nn.CrossEntropyLoss() #please note we are using \"CrossEntropyLoss\" here\n",
        "optimiser = optim.Adam(skip_gram_model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNys5HOdISK-",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.3. Train Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae8i7Z2kIef-",
        "colab_type": "code",
        "outputId": "afb08ae0-21a6-489c-be4a-356d88265331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_len = len(skip_grams_target)\n",
        "epoch_count = 0\n",
        "        \n",
        "for epoch in range(1):\n",
        "     epoch_count += 1  \n",
        "     for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "       inputs_torch = to_one_hot(inputs,len(vocab_to_int)).to(device)\n",
        "       labels_torch = labels.to(device)\n",
        "       \n",
        "       skip_gram_model.train()\n",
        "       # zero the parameter gradients\n",
        "       optimiser.zero_grad()\n",
        "\n",
        "       # forward + backward + optimize\n",
        "       outputs = skip_gram_model(inputs_torch)\n",
        "       loss = criterion(outputs, labels_torch) # We don't need to calcualte logsoftmax here\n",
        "       loss.backward()\n",
        "       optimiser.step()\n",
        "       if batch_idx == 0:\n",
        "         print('epoch: %d, loss: %.4f' %(0, loss))\n",
        "       if batch_idx % 1000 == 0:\n",
        "        print(' Iteration: %d, loss: %.4f' %(batch_idx, loss))\n",
        "     print('epoch: %d, loss: %.4f' %(epoch_count, loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 10.6703\n",
            " Iteration: 0, loss: 10.6703\n",
            " Iteration: 1000, loss: 9.5605\n",
            " Iteration: 2000, loss: 8.1712\n",
            " Iteration: 3000, loss: 7.8316\n",
            " Iteration: 4000, loss: 7.6837\n",
            " Iteration: 5000, loss: 7.7350\n",
            " Iteration: 6000, loss: 7.6231\n",
            " Iteration: 7000, loss: 7.4257\n",
            " Iteration: 8000, loss: 7.5012\n",
            " Iteration: 9000, loss: 7.6593\n",
            " Iteration: 10000, loss: 7.5217\n",
            " Iteration: 11000, loss: 7.6611\n",
            " Iteration: 12000, loss: 7.4782\n",
            " Iteration: 13000, loss: 7.5563\n",
            " Iteration: 14000, loss: 7.4403\n",
            " Iteration: 15000, loss: 7.4649\n",
            " Iteration: 16000, loss: 7.4638\n",
            " Iteration: 17000, loss: 7.4529\n",
            " Iteration: 18000, loss: 7.6235\n",
            " Iteration: 19000, loss: 7.5052\n",
            " Iteration: 20000, loss: 7.3947\n",
            " Iteration: 21000, loss: 7.4397\n",
            " Iteration: 22000, loss: 7.5182\n",
            " Iteration: 23000, loss: 7.4472\n",
            " Iteration: 24000, loss: 7.3619\n",
            " Iteration: 25000, loss: 7.4264\n",
            " Iteration: 26000, loss: 7.4095\n",
            " Iteration: 27000, loss: 7.4824\n",
            " Iteration: 28000, loss: 7.4344\n",
            " Iteration: 29000, loss: 7.2796\n",
            " Iteration: 30000, loss: 7.5384\n",
            " Iteration: 31000, loss: 7.4815\n",
            " Iteration: 32000, loss: 7.5152\n",
            " Iteration: 33000, loss: 7.4510\n",
            " Iteration: 34000, loss: 7.4221\n",
            " Iteration: 35000, loss: 7.4807\n",
            " Iteration: 36000, loss: 7.4058\n",
            " Iteration: 37000, loss: 7.4353\n",
            " Iteration: 38000, loss: 7.4388\n",
            " Iteration: 39000, loss: 7.4621\n",
            " Iteration: 40000, loss: 7.3123\n",
            " Iteration: 41000, loss: 7.4274\n",
            " Iteration: 42000, loss: 7.4653\n",
            " Iteration: 43000, loss: 7.4638\n",
            " Iteration: 44000, loss: 7.3436\n",
            " Iteration: 45000, loss: 7.5106\n",
            " Iteration: 46000, loss: 7.3692\n",
            " Iteration: 47000, loss: 7.3627\n",
            " Iteration: 48000, loss: 7.5108\n",
            " Iteration: 49000, loss: 7.5998\n",
            " Iteration: 50000, loss: 7.3952\n",
            " Iteration: 51000, loss: 7.4839\n",
            " Iteration: 52000, loss: 7.3538\n",
            " Iteration: 53000, loss: 7.3775\n",
            " Iteration: 54000, loss: 7.2694\n",
            " Iteration: 55000, loss: 7.4415\n",
            " Iteration: 56000, loss: 7.4205\n",
            " Iteration: 57000, loss: 7.5476\n",
            " Iteration: 58000, loss: 7.3872\n",
            " Iteration: 59000, loss: 7.3225\n",
            " Iteration: 60000, loss: 7.4548\n",
            " Iteration: 61000, loss: 7.3260\n",
            " Iteration: 62000, loss: 7.4028\n",
            " Iteration: 63000, loss: 7.2466\n",
            " Iteration: 64000, loss: 7.2553\n",
            " Iteration: 65000, loss: 7.4693\n",
            " Iteration: 66000, loss: 7.3398\n",
            " Iteration: 67000, loss: 7.4345\n",
            " Iteration: 68000, loss: 7.6511\n",
            " Iteration: 69000, loss: 7.3621\n",
            " Iteration: 70000, loss: 7.3260\n",
            " Iteration: 71000, loss: 7.2788\n",
            " Iteration: 72000, loss: 7.4427\n",
            " Iteration: 73000, loss: 7.3177\n",
            " Iteration: 74000, loss: 7.3841\n",
            " Iteration: 75000, loss: 7.4843\n",
            " Iteration: 76000, loss: 7.3387\n",
            " Iteration: 77000, loss: 7.3165\n",
            " Iteration: 78000, loss: 7.3312\n",
            "epoch: 1, loss: 7.5048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3uICZ7LzoG1_"
      },
      "source": [
        "### 2.1.4. Save Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLIrJeMR8oS9",
        "colab_type": "code",
        "outputId": "040c18b4-5ba0-4f5e-af5c-75a9fc16cbf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "torch.save(skip_gram_model, '/content/drive/My Drive/word_embedding.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SkipGram. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn16xrDrIs8B",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.5. Load Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IebpYFsIvgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable \n",
        "\n",
        "class SkipGram(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SkipGram, self).__init__()\n",
        "        self.linear1 = nn.Linear(voc_size, embedding_size,bias=False)\n",
        "        self.linear2 = nn.Linear(embedding_size, voc_size,bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.linear1(x)\n",
        "        out = self.linear2(hidden)\n",
        "        return out\n",
        "\n",
        "id = '1Pv9s7gmJxllyF6zN7aX8il8k3JmQjRWA'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('word_embedding.pt')\n",
        "\n",
        "skip_gram_model_load = torch.load('word_embedding.pt')\n",
        "weight1 = skip_gram_model_load.linear1.weight.data\n",
        "trained_embeddings = weight1.detach().cpu().T.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T0ap96aeGlIk"
      },
      "source": [
        "## 2.2. Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d16v3oKaGlI0"
      },
      "source": [
        "### 2.2.1. Data Preprocessing for Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AKbLnN-3GlI1"
      },
      "source": [
        "most of the pre-process works have already been done in the previous sessions.\n",
        "So the only pre-processing work that we will be doing for training our character embedding is padding.\n",
        "\n",
        "As we can see, the longest words in our dictonary has 20 characters, hence we will be pad all the inputs to character embedding to have a length of 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2CUCL1cGlI2",
        "outputId": "f36eda5a-98eb-45b5-99fc-479e980a3b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "#Assume that we have the following character instances\n",
        "char_arr = ['a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
        "            'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
        "\n",
        "            'o', 'p', 'q', 'r', 's', 't', 'u',\n",
        "            'v', 'w', 'x', 'y', 'z','pad']\n",
        "\n",
        "# one-hot encoding and decoding \n",
        "# {'a': 0, 'b': 1, 'c': 2, ..., 'j': 9, 'k', 10, ...}\n",
        "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
        "dic_len = len(num_dic)\n",
        "\n",
        "word_len = {}\n",
        "\n",
        "list_words = list(vocab_to_int.keys())\n",
        "for i in range(len(list_words)):\n",
        "  char_tmp = [num_dic[n] for n in list_words[i]]\n",
        "  word_len[list_words[i]] = len(char_tmp) \n",
        "word_len = {k: v for k, v in sorted(word_len.items(), key=lambda item: item[1],reverse=True)}\n",
        "max_word_len = list(word_len.items())[0][1]\n",
        "print(max_word_len)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DO-dRf7AMoM",
        "colab_type": "code",
        "outputId": "75c8600c-d1a2-467e-b756-a47abba7d3d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Make a batch to have sequence data for input and ouput\n",
        "def make_batch(seq_data):\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "    \n",
        "    for seq in seq_data:\n",
        "        input_data = list([num_dic[n] for n in seq])\n",
        "        for i in range(max_word_len - len(input_data)):\n",
        "          input_data.append(26) \n",
        "        target = trained_embeddings[vocab_to_int[seq]]\n",
        "        \n",
        "        input_batch.append(input_data)      \n",
        "        target_batch.append(target)\n",
        "\n",
        "    return input_batch, target_batch\n",
        "\n",
        "# Preparing input\n",
        "input_batch, target_batch = make_batch(all_words)\n",
        "# Convert input into tensors and move them to GPU by uting tensor.to(device)\n",
        "print(len(input_batch))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11385282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgiOPcsTGlI6"
      },
      "source": [
        "### 2.2.2. Build Character Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4NtqFFcjGlI7"
      },
      "source": [
        "Here are justifications for the hyperparameter choices:\n",
        ">\n",
        "1. Number of Epoch = 30\n",
        "  * Reason: Based on trial and errors, the losses will be converged after 30 epoch.   \n",
        "\n",
        "2. Batch Size = 1000\n",
        "  * Reason: Given the large dataset that we are working with, I tried to set the batch size as high as possible to speed up the training process. Due to the RAM constraints on the CPU in Colab, 1000 batch size is roughtly the highest batch size I can set.    \n",
        "  \n",
        "3. Learning Rate = 0.0001\n",
        "  * Reason: After multiple trial and errors, this learning rate gives the lowest and the most stable losses.\n",
        "\n",
        "6. Embedding Size = 100\n",
        "  * Reason: After trying out different embedding sizes, I found that there is no signifcant difference in losses between embedding size of 100 and 300, whlist training with embedding size = 100 is signficantly faster. However, dropping the embedding size from 100 to 50 signifcantly increased the losses, which is not desired. Thus, the embedding size was set at 100.  \n",
        "\n",
        "Note that, even though I understand that the losses from training the word embedding may not indicates its effectiveness in the end-application (which is sentiment analysis in this case). However, due to the time constraints, I am unable to run the end-to-end process (training word embedding + training character embedding + sentiment analysis) multiple times to find the best hyperparameter for training the character embedding.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGzXW6CCXZ_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Setting hyperparameters\n",
        "learning_rate = 0.0001\n",
        "n_hidden = 128\n",
        "total_epoch = 50\n",
        "batch_size = 1000\n",
        "n_layers = 2\n",
        "# number of inputs (dimension of input vector) = 27\n",
        "n_input = dic_len\n",
        "word_embedding_size = trained_embeddings.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jj3YZ3PWGlI8",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "device = 'cuda'\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lstm = nn.LSTM(n_input, n_hidden,num_layers = n_layers, batch_first =True,bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden * 2,word_embedding_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x,(h_n,_) = self.lstm(x)\n",
        "        #concat the last hidden state from two direction\n",
        "        hidden_out =torch.cat((h_n.view(n_layers,2,-1,n_hidden)[1,0,:,:],h_n.view(n_layers,2,-1,n_hidden)[1,1,:,:]),1)\n",
        "        x = self.linear(hidden_out)\n",
        "        return x, hidden_out\n",
        "\n",
        "# Move the model to GPU\n",
        "net = Net().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "46W0zFfWGlI_"
      },
      "source": [
        "### 2.1.4. Train Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJSso4qTW-Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_char_data = TensorDataset(torch.from_numpy(np.array(input_batch)), torch.from_numpy(np.array(target_batch)))\n",
        "train_char_loader = DataLoader(train_char_data, shuffle=True, batch_size=batch_size, num_workers = 4, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_yvdYBCBXBn",
        "colab_type": "code",
        "outputId": "9f2d6f63-697a-4574-9cc3-5f7eb7e661ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "source": [
        "epoch_count = 0\n",
        "        \n",
        "for epoch in range(total_epoch):\n",
        "     epoch_count += 1  \n",
        "     for batch_idx, (inputs, labels) in enumerate(train_char_loader):\n",
        "       inputs_torch = to_one_hot(inputs,dic_len).to(device)\n",
        "       labels_torch = labels.to(device)\n",
        "       \n",
        "       net.train()\n",
        "       # zero the parameter gradients\n",
        "       optimizer.zero_grad()\n",
        "\n",
        "       # forward + backward + optimize\n",
        "       outputs,_ = net(inputs_torch)\n",
        "       loss = criterion(outputs, labels_torch)\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "       if epoch_count == 1 and batch_idx == 0:\n",
        "         print('epoch: %d, loss: %.7f' %(0, loss))\n",
        "     print('epoch: %d, loss: %.7f' %(epoch_count, loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.0199098\n",
            "epoch: 1, loss: 0.0012489\n",
            "epoch: 2, loss: 0.0006878\n",
            "epoch: 3, loss: 0.0004288\n",
            "epoch: 4, loss: 0.0003632\n",
            "epoch: 5, loss: 0.0002016\n",
            "epoch: 6, loss: 0.0001986\n",
            "epoch: 7, loss: 0.0001720\n",
            "epoch: 8, loss: 0.0001560\n",
            "epoch: 9, loss: 0.0001180\n",
            "epoch: 10, loss: 0.0001096\n",
            "epoch: 11, loss: 0.0001536\n",
            "epoch: 12, loss: 0.0001326\n",
            "epoch: 13, loss: 0.0001496\n",
            "epoch: 14, loss: 0.0001168\n",
            "epoch: 15, loss: 0.0001258\n",
            "epoch: 16, loss: 0.0000939\n",
            "epoch: 17, loss: 0.0000809\n",
            "epoch: 18, loss: 0.0000928\n",
            "epoch: 19, loss: 0.0000878\n",
            "epoch: 20, loss: 0.0001030\n",
            "epoch: 21, loss: 0.0000928\n",
            "epoch: 22, loss: 0.0000599\n",
            "epoch: 23, loss: 0.0000672\n",
            "epoch: 24, loss: 0.0000611\n",
            "epoch: 25, loss: 0.0001030\n",
            "epoch: 26, loss: 0.0000595\n",
            "epoch: 27, loss: 0.0000538\n",
            "epoch: 28, loss: 0.0000532\n",
            "epoch: 29, loss: 0.0000659\n",
            "epoch: 30, loss: 0.0000421\n",
            "epoch: 31, loss: 0.0000659\n",
            "epoch: 32, loss: 0.0000564\n",
            "epoch: 33, loss: 0.0000472\n",
            "epoch: 34, loss: 0.0000962\n",
            "epoch: 35, loss: 0.0000305\n",
            "epoch: 36, loss: 0.0000675\n",
            "epoch: 37, loss: 0.0000339\n",
            "epoch: 38, loss: 0.0000477\n",
            "epoch: 39, loss: 0.0000333\n",
            "epoch: 40, loss: 0.0000777\n",
            "epoch: 41, loss: 0.0000435\n",
            "epoch: 42, loss: 0.0000430\n",
            "epoch: 43, loss: 0.0000334\n",
            "epoch: 44, loss: 0.0000347\n",
            "epoch: 45, loss: 0.0000370\n",
            "epoch: 46, loss: 0.0000391\n",
            "epoch: 47, loss: 0.0000786\n",
            "epoch: 48, loss: 0.0000386\n",
            "epoch: 49, loss: 0.0000362\n",
            "epoch: 50, loss: 0.0000624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R5Bym9bBGlJE"
      },
      "source": [
        "### 2.1.5. Save Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggTsYIm7GlJF",
        "outputId": "a1b6ab0d-ce22-44e7-ad39-98c706671c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "torch.save(net, '/content/drive/My Drive/character_embedding.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JwOI-wIKGlJI"
      },
      "source": [
        "### 2.1.6. Load Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-jyj-lOHWWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.autograd import Variable \n",
        "\n",
        "### Setting hyperparameters\n",
        "learning_rate = 0.0001\n",
        "n_hidden = 128\n",
        "total_epoch = 50\n",
        "batch_size = 1000\n",
        "n_layers = 2\n",
        "# number of inputs (dimension of input vector) = 27\n",
        "n_input = dic_len\n",
        "word_embedding_size = trained_embeddings.shape[1]\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lstm = nn.LSTM(n_input, n_hidden,num_layers = n_layers, batch_first =True,bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden * 2,word_embedding_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x,(h_n,_) = self.lstm(x)\n",
        "        #concat the last hidden state from two direction\n",
        "        hidden_out =torch.cat((h_n.view(n_layers,2,-1,n_hidden)[1,0,:,:],h_n.view(n_layers,2,-1,n_hidden)[1,1,:,:]),1)\n",
        "        x = self.linear(hidden_out)\n",
        "        return x, hidden_out\n",
        "\n",
        "id = '1MXa9Le0F1Y39kJNL5kcoYhuXzAgai4Wb'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('character_embedding.pt')\n",
        "\n",
        "net_load = torch.load('character_embedding.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlCeWT8eeLnd",
        "colab_type": "text"
      },
      "source": [
        "## 2.3. Sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwA-NN3EJ4Ig",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1. Apply/Import Word Embedding and Character Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAMJrxx-iOVn",
        "colab_type": "text"
      },
      "source": [
        "Following steps were taken in this session:\n",
        ">\n",
        "1. Numeric encoding the training and test lables.('pos' -> 1, 'neg' -> 2)\n",
        "\n",
        "2. Adding a token to represent the paddings ('padword') to out dictionary. \n",
        "  \n",
        "3. Create the corresponding word & character embeddings for 'padword' (zeros)\n",
        "\n",
        "4. Decide the max length for our reviews.\n",
        "  * Set maximum length of the review to be 1027, which is the 60th percentile in terms of review length. The argument is that review length increased at a significantly faster rate after 60th percentile, so I think that would be a natural cut-off.\n",
        "\n",
        "5. Finally, we created the data batches for training and testing. The batch size was set to 100 purely based on concern about the RAM limit.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7PKX1gIePA2",
        "colab_type": "code",
        "outputId": "f6349592-0c75-4095-efff-9cb4397030f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "# 1=positive, 0=negative label conversion\n",
        "\n",
        "sentiments_train_int = np.array([1 if sentiment == 'pos' else 0 for sentiment in sentiments_train])\n",
        "sentiments_test_int = np.array([1 if sentiment == 'pos' else 0 for sentiment in sentiments_test])\n",
        "\n",
        "print(len(reviews_train))\n",
        "print(len(sentiments_train_int))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n",
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf0sJ_opxruf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "# Add \"padword\" to existing dictionary\n",
        "vocab_to_int.update({'padword':len(vocab)})\n",
        "vocab.append(\"padword\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfnLdBX_wXLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77152cbe-e17a-4eb8-e8dc-0064c27eba83"
      },
      "source": [
        "print(len(vocab))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeFmyvfX1MnQ",
        "colab_type": "code",
        "outputId": "2dd80505-722d-476b-ba8d-24868b0b4564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "# Add \"padword\"'s corresponding word embedding\n",
        "trained_word_embeddings = np.vstack((trained_embeddings,np.zeros(100))) \n",
        "print(trained_embeddings.shape)\n",
        "print(trained_word_embeddings.shape)\n",
        "print(trained_word_embeddings[trained_word_embeddings.shape[0]-1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(43054, 100)\n",
            "(43055, 100)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "avIYeHhSwQdD",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "def vocab_to_character_embeddings(voc_cab):\n",
        "    trained_character_embeddings = []    \n",
        "    for w in voc_cab:\n",
        "      if w != 'padword':\n",
        "        input_data = list([num_dic[n] for n in w])\n",
        "        for i in range(max_word_len - len(input_data)):\n",
        "          input_data.append(26)\n",
        "        input_onehot = to_one_hot(torch.from_numpy(np.array(input_data)),27).view(1,20,27).to('cuda')\n",
        "        _,hidden_output = net_load(input_onehot)\n",
        "        trained_character_embeddings.append(hidden_output.view(-1).detach().cpu().numpy())\n",
        "      else:\n",
        "        trained_character_embeddings.append(np.zeros((256)))\n",
        "\n",
        "    return np.array(trained_character_embeddings)\n",
        "\n",
        "trained_character_embeddings = vocab_to_character_embeddings(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI3cP0aRiqSF",
        "colab_type": "code",
        "outputId": "d3798696-cb08-431b-fb29-94c491f464f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(trained_character_embeddings.shape)\n",
        "print(len(trained_character_embeddings))\n",
        "print(len(vocab))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(43055, 256)\n",
            "43055\n",
            "43055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6VTRX3Ht-D1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "89b49d20-d8de-4cfd-ecfd-0440c18e5a3e"
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "import matplotlib\n",
        "\n",
        "len1 = []\n",
        "for r in reviews:\n",
        "  len1.append(len(r)) \n",
        "\n",
        "len2 =[]\n",
        "\n",
        "for i in [0,10,20,30,40,50,60,70,80,90,95]:\n",
        "  len2.append(int(np.percentile(np.array(len1),i)))\n",
        "  matplotlib.pyplot.plot(len2)\n",
        "\n",
        "# Before 60th percentile, between 20th and 60th percentile, the rate of increase in length is a linear relationship\n",
        "# After 60th percentile, the length of the reviews increase at an exponential rate\n",
        "# Thus, it seems to be a natural cut-off, and we will use the 60th percentile as the max length for all the reviews,\n",
        "\n",
        "max_review_len = int(np.percentile(np.array(len1),60))\n",
        "print(max_review_len)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_vx1FnRBQLr",
        "colab_type": "code",
        "outputId": "301faaa6-9bc8-42e7-c486-cfe09d355919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "# Make a batch to have sequence data for input and ouput\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "  \n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def data_prep_sentiment(reviews,sentiments):\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    count = -1\n",
        "    for r in reviews:\n",
        "      count+=1\n",
        "      words = []\n",
        "      if len(word_tokenize(r)) < max_review_len:\n",
        "        for i in range(max_review_len - len(word_tokenize(r))):\n",
        "            words.append(vocab_to_int[\"padword\"]) \n",
        "        for w in word_tokenize(r):\n",
        "            word = vocab_to_int[w]\n",
        "            words.append(word)\n",
        "      else:\n",
        "        r_temp = word_tokenize(r)\n",
        "        for i in range(max_review_len):\n",
        "            word = vocab_to_int[r_temp[i]]\n",
        "            words.append(word)\n",
        "        \n",
        "      x_train.append(words)\n",
        "      y_train.append(sentiments[count])\n",
        "\n",
        "    return x_train, y_train\n",
        "\n",
        "# Preparing input\n",
        "x_train, y_train = data_prep_sentiment(reviews_train,sentiments_train_int)\n",
        "x_test, y_test = data_prep_sentiment(reviews_test,sentiments_test_int)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0P25tIn5gip",
        "colab_type": "code",
        "outputId": "7aabf419-16ae-4619-95b4-6431e886c9d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(trained_character_embeddings.shape)\n",
        "print(trained_word_embeddings.shape)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(43055, 256)\n",
            "(43055, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3oyartpIqPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "# create Tensor datasets\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "batch_size = 100\n",
        "\n",
        "all_sequence_data = TensorDataset(torch.from_numpy(np.array(x_train)),torch.from_numpy(np.array(y_train)),torch.from_numpy(np.array(x_test)),torch.from_numpy(np.array(y_test))) \n",
        "all_sequence_loader = DataLoader(all_sequence_data, batch_size=batch_size, num_workers = 4, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpYCL17JKZxl",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.2. Build Sequence Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R204UIyDKhZ4",
        "colab_type": "text"
      },
      "source": [
        "Here are justifications for the hyperparameter choices:\n",
        ">\n",
        "1. Total Number of Epoch = 25\n",
        "  * Reason: Based on the trial and error, I found that optimal accuracy was achieved at after 20th epoch, but I would like to show that the model will overfit if we keep on training after epoch 20, so I set the total number of epoch to be 25.\n",
        "\n",
        "2. Batch Size = 100\n",
        "  * Reason: Based on trial and errors, this batch size is the sweet spot which gives a stable decrease in losses after each epoch, while it does not seem to be too slow to train, and finally this batch size will not cause the RAM and GPU memory usage to exceeds Colab's limit.\n",
        "  \n",
        "3. Learning Rate = 0.001\n",
        "  * Reason: This is purely based on trial and errors.\n",
        "\n",
        "4. Number of neuron in the LSTM = 128\n",
        "  * Reason: Purely based on trial and errors, the GPU memory limits were also being considered there. If this parameter is too big, the GPU won't have enough memory to construct the model.\n",
        "\n",
        "5. Probability of dropout = 0.05\n",
        "  * Reason: Purely based on trial and errors, I have tried 0.2 before as well, but it would cause the model to under-fit.\n",
        "\n",
        "Overall network architecture is very simple due to the memory constraints of the GPU and to save runtime. I believe a bigger or more complex model with higher maximum review length will probably lead to a higher F1 score, however, I ran out of time to test them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6GuZAznGDpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Please assign values to these variables by using other variables (instead of hard code)\n",
        "n_input = trained_word_embeddings.shape[1] + trained_character_embeddings.shape[1]\n",
        "\n",
        "#Please decide the hyperparameters here by yourself\n",
        "n_hidden = 128\n",
        "total_epoch = 20\n",
        "learning_rate = 0.001\n",
        "shown_interval = 1\n",
        "\n",
        "class Sentiment_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Sentiment_Model, self).__init__()\n",
        "        self.lstm = nn.LSTM(n_input, n_hidden, num_layers=1, batch_first =True, bidirectional=True)\n",
        "        self.linear = nn.Linear(n_hidden * 2,1)\n",
        "        self.dropout = nn.Dropout(0.05)\n",
        "        self.sigmoid = nn.Sigmoid() \n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x,_ = self.lstm(x)\n",
        "        x = self.linear(x[:,-1,:])\n",
        "        x = self.dropout(x) \n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BaOiaGRLW7R",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.3. Train Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-8Zm7tBJQb9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "e6766c18-4421-4ece-e809-3726a559387d"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "device = 'cuda'\n",
        "Sentiment_Model = Sentiment_Model().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Please find which optimizer provide higher f1\n",
        "optimizer = optim.Adam(Sentiment_Model.parameters(), lr=learning_rate) \n",
        "\n",
        "f1_list_train = []\n",
        "f1_list_test = []\n",
        "\n",
        "for epoch in range(total_epoch):\n",
        "    predictions_train = [] \n",
        "    predictions_test = []\n",
        "\n",
        "    for batch_idx, (inputs, labels, inputs_test, labels_test) in enumerate(all_sequence_loader):      \n",
        "      reviews_embeddings = []\n",
        "      \n",
        "      for r in inputs:\n",
        "        inputs_embedding = []\n",
        "        \n",
        "        for w in r:\n",
        "          trained_word_embedding = trained_word_embeddings[w].reshape(1,-1)\n",
        "          trained_character_embedding = trained_character_embeddings[w].reshape(1,-1)\n",
        "          inputs_embedding_temp = np.hstack((trained_word_embedding,trained_character_embedding))\n",
        "          inputs_embedding.append(inputs_embedding_temp)\n",
        "        \n",
        "        reviews_embeddings.append(np.array(inputs_embedding).reshape(max_review_len,n_input))\n",
        "      \n",
        "      inputs_embeddings = torch.from_numpy(np.array(reviews_embeddings)).float() \n",
        "      inputs_torch = inputs_embeddings.to(device)\n",
        "      labels_torch = labels.to(device)\n",
        "    \n",
        "      reviews_embeddings_test = []\n",
        "      for r in inputs_test:\n",
        "        inputs_embedding = []\n",
        "        \n",
        "        for w in r:\n",
        "          trained_word_embedding = trained_word_embeddings[w].reshape(1,-1)\n",
        "          trained_character_embedding = trained_character_embeddings[w].reshape(1,-1)\n",
        "          inputs_embedding_temp = np.hstack((trained_word_embedding,trained_character_embedding))\n",
        "          inputs_embedding.append(inputs_embedding_temp)\n",
        "        \n",
        "        reviews_embeddings_test.append(np.array(inputs_embedding).reshape(max_review_len,n_input))\n",
        "      \n",
        "      inputs_embeddings_test = torch.from_numpy(np.array(reviews_embeddings_test)).float() \n",
        "      inputs_torch_test = inputs_embeddings_test.to(device)\n",
        "      labels_torch_test = labels_test.to(device)\n",
        "\n",
        "      Sentiment_Model.eval()\n",
        "      outputs_test = Sentiment_Model(inputs_torch_test).view(-1)\n",
        "      loss_test = criterion(outputs_test, labels_torch_test.float())\n",
        "      \n",
        "      Sentiment_Model.train()\n",
        "      optimizer.zero_grad()\n",
        "      outputs = Sentiment_Model(inputs_torch).view(-1)\n",
        "      loss = criterion(outputs, labels_torch.float())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      Sentiment_Model.eval()\n",
        "        \n",
        "      outputs_train = Sentiment_Model(inputs_torch).view(-1) \n",
        "      train_loss = criterion(outputs_train, labels_torch.float())\n",
        "      predicted_train = outputs_train.detach().cpu().numpy()\n",
        "        \n",
        "      for i in range(predicted_train.shape[0]):\n",
        "        if predicted_train[i] > 0.5:\n",
        "          predictions_train.append(1)\n",
        "        else:\n",
        "          predictions_train.append(0)\n",
        "\n",
        "      outputs_test = Sentiment_Model(inputs_torch_test).view(-1) \n",
        "      test_loss = criterion(outputs_test, labels_torch_test.float())\n",
        "      predicted_test = outputs_test.detach().cpu().numpy()\n",
        "        \n",
        "      for i in range(predicted_test.shape[0]):\n",
        "        if predicted_test[i] > 0.5:\n",
        "          predictions_test.append(1)\n",
        "        else:\n",
        "          predictions_test.append(0)\n",
        "\n",
        "    if epoch % shown_interval == 0:\n",
        "      train_F1= round(f1_score(np.array(predictions_train),np.array(y_train)),4)      \n",
        "      test_F1= round(f1_score(np.array(predictions_test),np.array(y_test)),4)\n",
        "      print('Epoch: %d, train loss: %.5f, train_F1: %.4f, test loss: %.5f, test_F1: %.4f'%(epoch + 1, train_loss.item(), train_F1, test_loss.item(), test_F1))\n",
        "\n",
        "      f1_list_train.append(train_F1)\n",
        "      f1_list_test.append(test_F1)\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, train loss: 0.65479, train_F1: 0.6133, test loss: 0.62483, test_F1: 0.6136\n",
            "Epoch: 2, train loss: 0.56883, train_F1: 0.6845, test loss: 0.53443, test_F1: 0.6856\n",
            "Epoch: 3, train loss: 0.65964, train_F1: 0.6762, test loss: 0.64156, test_F1: 0.6777\n",
            "Epoch: 4, train loss: 0.59021, train_F1: 0.6766, test loss: 0.60961, test_F1: 0.6757\n",
            "Epoch: 5, train loss: 0.66596, train_F1: 0.6682, test loss: 0.67578, test_F1: 0.6605\n",
            "Epoch: 6, train loss: 0.64229, train_F1: 0.6775, test loss: 0.65813, test_F1: 0.6665\n",
            "Epoch: 7, train loss: 0.49066, train_F1: 0.7621, test loss: 0.49663, test_F1: 0.7534\n",
            "Epoch: 8, train loss: 0.47378, train_F1: 0.8038, test loss: 0.42361, test_F1: 0.8008\n",
            "Epoch: 9, train loss: 0.40060, train_F1: 0.8300, test loss: 0.37011, test_F1: 0.8237\n",
            "Epoch: 10, train loss: 0.36552, train_F1: 0.8459, test loss: 0.32410, test_F1: 0.8397\n",
            "Epoch: 11, train loss: 0.38846, train_F1: 0.8568, test loss: 0.33815, test_F1: 0.8479\n",
            "Epoch: 12, train loss: 0.36043, train_F1: 0.8651, test loss: 0.32550, test_F1: 0.8535\n",
            "Epoch: 13, train loss: 0.35961, train_F1: 0.8707, test loss: 0.30585, test_F1: 0.8562\n",
            "Epoch: 14, train loss: 0.32909, train_F1: 0.8768, test loss: 0.27919, test_F1: 0.8577\n",
            "Epoch: 15, train loss: 0.33605, train_F1: 0.8829, test loss: 0.27002, test_F1: 0.8635\n",
            "Epoch: 16, train loss: 0.31124, train_F1: 0.8879, test loss: 0.27423, test_F1: 0.8629\n",
            "Epoch: 17, train loss: 0.31402, train_F1: 0.8915, test loss: 0.27412, test_F1: 0.8651\n",
            "Epoch: 18, train loss: 0.31337, train_F1: 0.8923, test loss: 0.29129, test_F1: 0.8645\n",
            "Epoch: 19, train loss: 0.31343, train_F1: 0.8970, test loss: 0.28200, test_F1: 0.8645\n",
            "Epoch: 20, train loss: 0.31533, train_F1: 0.9016, test loss: 0.28570, test_F1: 0.8672\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56ZqmDcF2cTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(Sentiment_Model.state_dict(), '/content/drive/My Drive/Sentiment_Model.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4pkkZT_1c5E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "eed47549-e8ba-4ed5-a699-35efad3bd1bd"
      },
      "source": [
        "# Train another 5 Epoch to check whether this model has converged\n",
        "\n",
        "for epoch in range(20,25):\n",
        "    predictions_train = [] \n",
        "    predictions_test = []\n",
        "\n",
        "    for batch_idx, (inputs, labels, inputs_test, labels_test) in enumerate(all_sequence_loader):      \n",
        "      reviews_embeddings = []\n",
        "      \n",
        "      for r in inputs:\n",
        "        inputs_embedding = []\n",
        "        \n",
        "        for w in r:\n",
        "          trained_word_embedding = trained_word_embeddings[w].reshape(1,-1)\n",
        "          trained_character_embedding = trained_character_embeddings[w].reshape(1,-1)\n",
        "          inputs_embedding_temp = np.hstack((trained_word_embedding,trained_character_embedding))\n",
        "          inputs_embedding.append(inputs_embedding_temp)\n",
        "        \n",
        "        reviews_embeddings.append(np.array(inputs_embedding).reshape(max_review_len,n_input))\n",
        "      \n",
        "      inputs_embeddings = torch.from_numpy(np.array(reviews_embeddings)).float() \n",
        "      inputs_torch = inputs_embeddings.to(device)\n",
        "      labels_torch = labels.to(device)\n",
        "    \n",
        "      reviews_embeddings_test = []\n",
        "      for r in inputs_test:\n",
        "        inputs_embedding = []\n",
        "        \n",
        "        for w in r:\n",
        "          trained_word_embedding = trained_word_embeddings[w].reshape(1,-1)\n",
        "          trained_character_embedding = trained_character_embeddings[w].reshape(1,-1)\n",
        "          inputs_embedding_temp = np.hstack((trained_word_embedding,trained_character_embedding))\n",
        "          inputs_embedding.append(inputs_embedding_temp)\n",
        "        \n",
        "        reviews_embeddings_test.append(np.array(inputs_embedding).reshape(max_review_len,n_input))\n",
        "      \n",
        "      inputs_embeddings_test = torch.from_numpy(np.array(reviews_embeddings_test)).float() \n",
        "      inputs_torch_test = inputs_embeddings_test.to(device)\n",
        "      labels_torch_test = labels_test.to(device)\n",
        "\n",
        "      Sentiment_Model.eval()\n",
        "      outputs_test = Sentiment_Model(inputs_torch_test).view(-1)\n",
        "      loss_test = criterion(outputs_test, labels_torch_test.float())\n",
        "      \n",
        "      Sentiment_Model.train()\n",
        "      optimizer.zero_grad()\n",
        "      outputs = Sentiment_Model(inputs_torch).view(-1)\n",
        "      loss = criterion(outputs, labels_torch.float())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      Sentiment_Model.eval()\n",
        "        \n",
        "      outputs_train = Sentiment_Model(inputs_torch).view(-1) \n",
        "      train_loss = criterion(outputs_train, labels_torch.float())\n",
        "      predicted_train = outputs_train.detach().cpu().numpy()\n",
        "        \n",
        "      for i in range(predicted_train.shape[0]):\n",
        "        if predicted_train[i] > 0.5:\n",
        "          predictions_train.append(1)\n",
        "        else:\n",
        "          predictions_train.append(0)\n",
        "\n",
        "      outputs_test = Sentiment_Model(inputs_torch_test).view(-1) \n",
        "      test_loss = criterion(outputs_test, labels_torch_test.float())\n",
        "      predicted_test = outputs_test.detach().cpu().numpy()\n",
        "        \n",
        "      for i in range(predicted_test.shape[0]):\n",
        "        if predicted_test[i] > 0.5:\n",
        "          predictions_test.append(1)\n",
        "        else:\n",
        "          predictions_test.append(0)\n",
        "\n",
        "    if epoch % shown_interval == 0:\n",
        "      train_F1= round(f1_score(np.array(predictions_train),np.array(y_train)),4)      \n",
        "      test_F1= round(f1_score(np.array(predictions_test),np.array(y_test)),4)\n",
        "      print('Epoch: %d, train loss: %.5f, train_F1: %.4f, test loss: %.5f, test_F1: %.4f'%(epoch + 1, train_loss.item(), train_F1, test_loss.item(), test_F1))\n",
        "\n",
        "      f1_list_train.append(train_F1)\n",
        "      f1_list_test.append(test_F1)\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21, train loss: 0.31232, train_F1: 0.9046, test loss: 0.29601, test_F1: 0.8664\n",
            "Epoch: 22, train loss: 0.31420, train_F1: 0.9096, test loss: 0.30772, test_F1: 0.8670\n",
            "Epoch: 23, train loss: 0.30215, train_F1: 0.9151, test loss: 0.29472, test_F1: 0.8651\n",
            "Epoch: 24, train loss: 0.28153, train_F1: 0.9161, test loss: 0.29577, test_F1: 0.8664\n",
            "Epoch: 25, train loss: 0.27377, train_F1: 0.9208, test loss: 0.29607, test_F1: 0.8661\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auz_sJVsSyhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(Sentiment_Model.state_dict(), '/content/drive/My Drive/Sentiment_Model - Overfit.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2feNpG-LZx2",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.4. Save Sequence Model\n",
        "(*This step has been done as part of training, please refer to the previous session for details*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zFo6YppL6w3",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.5. Load Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtNxLzDGMCan",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "177ad6e6-5927-4727-8cd1-c7f58536c065"
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "id = '18v8UNfPpcwkn_tzPeuAcfGHmymD0pjVv'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Sentiment_Model.pt')\n",
        "\n",
        "Sentiment_Model_load = Sentiment_Model().to('cuda')\n",
        "Sentiment_Model_load.load_state_dict(torch.load('Sentiment_Model.pt'))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4mpRpocePLN",
        "colab_type": "text"
      },
      "source": [
        "# 3 - Evaluation\n",
        "\n",
        "(*Please show your empirical evidence*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEW1zMgVMREr",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. Performance Evaluation\n",
        "\n",
        "\n",
        "You are required to provide the table with precision, recall, f1 of test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKbo1c4yxjw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "device = 'cuda'\n",
        "for epoch in range(1):\n",
        "    predictions_test = []\n",
        "\n",
        "    for batch_idx, (inputs, labels, inputs_test, labels_test) in enumerate(all_sequence_loader):      \n",
        "\n",
        "      reviews_embeddings_test = []\n",
        "      for r in inputs_test:\n",
        "        inputs_embedding = []\n",
        "        \n",
        "        for w in r:\n",
        "          trained_word_embedding = trained_word_embeddings[w].reshape(1,-1)\n",
        "          trained_character_embedding = trained_character_embeddings[w].reshape(1,-1)\n",
        "          inputs_embedding_temp = np.hstack((trained_word_embedding,trained_character_embedding))\n",
        "          inputs_embedding.append(inputs_embedding_temp)\n",
        "        \n",
        "        reviews_embeddings_test.append(np.array(inputs_embedding).reshape(max_review_len,n_input))\n",
        "      \n",
        "      inputs_embeddings_test = torch.from_numpy(np.array(reviews_embeddings_test)).float() \n",
        "      inputs_torch_test = inputs_embeddings_test.to(device)\n",
        "      labels_torch_test = labels_test.to(device)\n",
        "\n",
        "      Sentiment_Model_load.eval()\n",
        "        \n",
        "      outputs_test = Sentiment_Model_load(inputs_torch_test).view(-1) \n",
        "      predicted_test = outputs_test.detach().cpu().numpy()\n",
        "        \n",
        "      for i in range(predicted_test.shape[0]):\n",
        "        if predicted_test[i] > 0.5:\n",
        "          predictions_test.append(1)\n",
        "        else:\n",
        "          predictions_test.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPHCb-bneTI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "c44cc57a-00dc-4be7-a79b-3047944bdaa1"
      },
      "source": [
        "####################################\n",
        "######## Run This Cell #########\n",
        "####################################\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions_test,digits=4))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8644    0.8774    0.8708     12500\n",
            "           1     0.8755    0.8623    0.8689     12500\n",
            "\n",
            "    accuracy                         0.8698     25000\n",
            "   macro avg     0.8699    0.8698    0.8698     25000\n",
            "weighted avg     0.8699    0.8698    0.8698     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P28Z1k36MZuo",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Hyperparameter Testing\n",
        "Based on the graph below, the F1 score on test dataset started to converged and even decreased slightly after the 20th epoch, while the F1 score on training dataset continues to increase. That is a sign of over-fitting. Thus, the optimal number of epoch for the given hyper-parameters should be 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmN5Fxo65U6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "0bcb73b2-9789-4a46-9eb9-7592d85df29d"
      },
      "source": [
        "import matplotlib as matplot\n",
        "epoch_num = np.array(range(1,26))\n",
        "matplot.pyplot.plot(epoch_num,np.array(f1_list_test),color=\"green\",label=\"test F1\")\n",
        "matplot.pyplot.plot(epoch_num,np.array(f1_list_train),color=\"red\",label=\"train F1\")\n",
        "matplot.pyplot.xlabel(\"Number of Epoch\")\n",
        "matplot.pyplot.ylabel(\"F1 scores\")\n",
        "matplot.pyplot.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "matplot.pyplot.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEGCAYAAABW/v0JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hUZd7/8fc3jRBqgFADBkITkCIBFVgpNrCAXbCuumLfR93HZ/G3tmXtj+7jruuqYHdd67qKVNEFNCBIQEF6R4KU0EkIkGTu3x9nkCG0ATI5yczndV1zZea0+R6CfrjPuc99m3MOERER8U+c3wWIiIjEOoWxiIiIzxTGIiIiPlMYi4iI+ExhLCIi4rMEvwsoK/Xq1XMZGRl+lyEiUqnMmjVrk3Mu7QSPUT8hIeFVoANq5B1OAJhXXFz8m65du24svTJqwjgjI4OcnBy/yxARqVTMbPWJHiMhIeHVhg0bnpyWlrY1Li5Oz8seQiAQsLy8vHbr169/FRhYer3+BSMiIieqQ1pa2g4F8eHFxcW5tLS07XhXDw5eX871iIhI9IlTEB9d8M/okLmrMBYREfGZwlhERCq1TZs2xT/11FPH3Qlt+PDh9Xfu3HnIPOzevXubjIyMDm3btm3Xtm3bdm+88UYqwBVXXJFRp06dTq1atWp/vN8bSmEsIiKV2ubNm+Nfe+21+se7/yuvvNIgPz//sHn49ttvr1i0aNGCRYsWLbjxxhu3Atx0002bRo0atfR4v7M0hbGIiFRqv/vd79LXrFlTpW3btu1uvfXWdICHHnqoQYcOHU5u3bp1u3vvvbcxwI4dO+L69OnTsk2bNu1atWrVfuTIkamPPfZY/Y0bNyb27t279WmnndY63O8cMGBAflpaWnFZnUPUPNokIiL+u+mzm5rO2zgvpSyP2aF+h12vD3p9zeHWP/fcc7kXXnhh1UWLFi0A+OSTT2ouW7Ysee7cuQudc5x99tktx40bV33Dhg0JDRs2LJo8efIy8FrUdevWLXnppZcaTJkyZUmjRo0OGa7XX399i+Tk5ADA5MmTFzds2LCkLM8PFMYiIpVTIAALF8I330BcHAwd6ndFFcb48eNrfv311zXbtWvXDmDXrl1xixYtSj7rrLN2/uEPf2h6++23Nxk0aND2/v3754dzvLfffnvFmWeeuSuSNSuMRUQqg6IimD3bC99vvoHsbNiyxVt3xhkVJoyP1IItL8457rnnnnX333//ptLrZs+eveBf//pXrYceeqjJl19+uePZZ59d50eNpSmMRUQqooICmD59f/hOnw67go2zli1h0CD41a+8V2amv7X6rFatWiUFBQW/9IEaMGDAjkcffbTx0KFDt9SqVSuwcuXKxKSkJFdUVGT169cvvuOOO7akpqaWvPbaa/UAqlWrVrJ9+/a4Ro0a+XYOCmMRkfLgHBQWws6dR36tXeu1emfPhuJiMINOneDmm73g7dULfAyNiqhhw4YlXbt2zW/VqlX7fv36bX/llVdy58+fn9ytW7e2ACkpKYF333135aJFi6o88MAD6XFxcSQkJLi///3vqwFuuOGGTf3792/doEGDvTNmzFgSzndedNFFzadPn15j69atCQ0aNOg4bNiwn++9996DWuLhMueiY9CUrKwsp7GpRcR3u3fD11/DhAkweTJs3Lg/aAOBo++flATdu+9v9fboAbVqRaxcM5vlnMs6kWPMmTNnVadOnY47iGLJnDlz6nXq1Cmj9HK1jEVEToRzsHixF77jx8OUKV4LOCnJa8V26gQ1aoT/ql4d4uP9PispZwpjEZFjtX07fPWVF8ATJsDq4MRHrVvDLbfAeedB795QrZq/dUqloTAWETma4mLvHu7EiV7r99tvoaTEa8medRYMG+YFcPPmflcqlZTCWESktJISmDMHJk3yXl9/7d3zBejaFX7/ey98zzgDEhP9rVWigsJYRCQQgB9/PDB8t23z1rVuDVdfDX37eq/6xz0EsshhKYxFJPaUlMCiRfvDd8oU2LzZW5eZCZdf7gVvnz7QuLGvpUpsiOhEEWbW38wWm9kyMxt2iPUnmdlXZjbXzCabWXrIuhvMbGnwdUMk6xSRKLVli3d/98034YEH4NJLoX17SEmBDh3g7ru9e8EDB8Jbb8FPP8GyZTBypNcaVhBXCicyhWLv3r1bbtq0Kezu6/fdd1/j+vXrd9w3peIdd9zRBOCJJ55Ia9asWQcz67pu3bpjbuhGrGVsZvHAi8A5QC4w08xGOecWhGz2LPC2c+4tM+sHPAlcZ2Z1gEeALMABs4L7bo1UvSJSSTkHS5fCggXeI0ZLlng/Fy+GTSGPviYkeK3eNm3gggu8UO7dGzIyfCtdysa+KRSHDRuWV3pdUVERiUe4rz9lypRlx/p9t91224bhw4dvCF3Wu3fv/Msuu2x7v3792hzr8SCyl6m7A8uccysAzOx9YBAQGsbtgPuC7ycBnwbfnwdMdM5tCe47EegPvBfBekWkMtizB2bN8kapys6GadP2X2IGaNDAC9xLLvHu97Zp472aN1dnqygVOoVi7969d1x00UXbH3nkkca1atUqWbFiRfKqVavmnX322Znr1q1L2rNnT9xtt9224b//+783ATRp0uSUnJychTt27IgbMGBAq+7du+fn5ORUb9Cgwd4JEyYsq169elgjY/Xs2bPwRM4hkmHcBAgdMDwXOK3UNnOAS4G/AJcANcys7mH2bRK5UkWkwtq61QvcfeE7c6YXyACtWnmXmHv0gI4dvfCtXdvfemPdTTc1ZV7ZTqFIhw67eD38KRRHjx5dY8GCBSnff//9/LZt2+4FePfdd1c1aNCgJD8/37p06dLu2muv3Vp6KsSffvop+R//+MeKHj16rD7//PNbvP3226l33HHHltLf9/LLLzf48MMP6wI8/vjjuZdddtmOEz1Fvztw/TfwNzP7NfA1sBYIe55IMxsKDAVo1qxZJOoTkfLknDeAxr7gzc6G+fO9dQkJ3mNFd97pjWzVo4fXChY5hI4dOxbsC2KAp59+usGYMWNqA6xfvz5x/vz5yQ0bNiwI3adJkyZ7evToUQjQpUuXXatWrapyqGMf6jL1iYpkGK8FmoZ8Tg8u+4Vz7me8ljFmVh24zDm3zczWAn1K7Tu59Bc450YAI8Abm7oMaxeR8hAIeGG7b2aib77xJkoAqFnTC9whQ6BnT2+85pSybXBJBByhBVueUlJSfhkIfPTo0TWmTJlSIycnZ1GNGjUC3bt3b1NYWHhQB+akpKRfciQ+Pt4daptIiWQYzwRamVlzvBAeDFwduoGZ1QO2OOcCwAPA68FVE4AnzCw1+Pnc4HoRqcz27vXu9+4L3qlTvcvQ4PVc3jc5Qq9eXm9njdEsYSg9hWJp27Zti69Vq1ZJjRo1At9//33ynDlzKtw4pRELY+dcsZndhRes8cDrzrn5ZjYcyHHOjcJr/T5pZg7vMvWdwX23mNmf8AIdYPi+zlwiUoHtmyZw1y7vVVAAubn7w3fGDG89ePd3L710fwA3b+5NFyhyjEpPoXjRRRdtD11/2WWXbR8xYkRaixYt2rdo0WJ3p06dCg53rOP12GOP1X/hhRcabt68ObFTp07t+vbtu/2DDz5YHe7+mkJRRA5v3z3cOXO814IF3iQJoWEb+nPXrkMfJy4OOnc+sOWr+70VgqZQLF+aQlFEjqygAObNg7lz94fv3LmwI9hR1Mxrvdat6927rV/f+1mtmvfzcO/r1fPu99as6e/5iVRgCmORWLRzp3e/Nidnf/guXeq1hMGbjahjR7j2Wm8+3o4dvXu41av7W7dIlFIYi8SCXbu88N03FvPMmd74zOCNStWxozf8Y6dO3uukk7xLyyLhCQQCAYuLi4uO+54REggEDAgcap3CWCQa7d7tjcm8L3xnzICiIu9Z3W7dvCkA+/aF007zWsEiJ2ZeXl5eu7S0tO0K5EMLBAKWl5dXC5h3qPUKY5FosHcvTJ++P3ynT/dGqYqLg6wsuO8+L3x79tSlZilzxcXFv1m/fv2r69ev70CEJyCqxALAvOLi4t8caqXCWKSy2rEDxo2Dzz6DsWO9Xs5m0KUL3HWXF76/+pU6TknEde3adSMw0O86KjOFsUhlkpsLo0Z5ATxpknfpOS0NLrsMLrrIm4UoNfXoxxGRCkVhLFKROec9bvTpp14Az5rlLW/dGu65BwYNgtNP10hVIpWcwlikoiku9iZI+Owz77Vypbf89NPhySfh4ouhbVt/axSRMqUwFqkI8vNhwgQvfMeMgS1boEoVOPtseOAB7xJ0w4Z+VykiEaIwFvHL+vXw+efeJeivvvJ6P6emwoUXepefzztPPZ9FYoTCWKS8OAeLFu2//DxjhrcsIwNuv90L4F69vGeBRSSm6L96kUgqLvae+R01ymsBL13qLe/aFf74Ry+ATzlFsxWJxDiFsUhZ+/lnGD/eewZ44kTv+d/ERO+533vugYEDIT3d7ypFpAJRGIucqKIimDbNC99x47yJFwAaN4bLL4f+/eGcc6BWLX/rjGK7i3cTb/Ekxif6XYrIcVEYixyPNWv2t36//NKbBSkhwbvn+/TTXgDr8nOZcc6RtyuP5VuWs3zr8v0/g+83FGwAIDEukZTEFFISU6iWVM37mVjtgM8pCd77pPgk9hTvYXfxbnaX7N7/PuS1p+TAZckJyTSq3oiG1RvSqHojGtU4+H2Dag2O+I+CvSV72Vq4la27t7K1cCvbdm/75f3W3VvJ35tPvMWTEJfwyys+7sDPB6yzeOpXq885meeU169DIkBhLBKuDRtg5Eh4/32YP99b1rQpDBkCAwZAv35RM/RkYVEha3euZc32NeTuyGXNDu/nuvx1xFkcyQnJJMcnk5yQTJWEKt7nhGSqxO9/v29dUnwSRvj/KHE48gryDgjb5VuXk783/5dtDKNJzSZkpmZyQasLyKidgZlRsLeAXUW72FW0i4KiggN+bi7cfMD6PSV7Dlt3ckIy9VLqHXRuhcWFrNu5juVblzN1zVQ27dp0UP2GUS+lnhfM1Ruwu3j3AaG7q2jXEc8/KT6JgAtQHCgO+8/s9PTTFcaVnMJY5Eic8zpg/e1v8NFH3iXpPn3g2We9AD75ZF9bvwEXYPa62YxZMob5efO98DhESB4qdKokVGH77u0HhO2+n4cKmbpV69KoRiOccwe1GPcU76EoUFSm55YUn0Tz2s3JrJPJmSedSWZqJpl1MslMzaR5anOSE5LL9PuOx96SvWzI38D6/PWsy1/Hup3r9r/PX8fGgo0kJyTTum5rUpNTSa2aSmpyKrWTa//yPvRn7eTaJMUnAd7VgH2hXOJKKA4UH/a1bx+pvBTGIodSWOi1gP/2N5g922vx3nGH92rd2tfSdu7ZycQVExmzZAxjl41lff56DCOzTiYlgZIDLq8WFhXiOPqMdqnJqTSt1ZT0mumc1uQ0mtb03u9bll4znZTElCMeoyRQ8sv3hl7y3Vuy95jPMbVqKk1qNCE+rmIP85kUn0TTWk1pWqtpmR/bzIi3+Ar/ZyBlQ2EsEmrlSnjpJXjtNW8UrA4dvM/XXuvrABxLNy9lzNIxjF4ymq9Xf01RoIhaVWrRv2V/Lmh1Af1b9ietWtpB+znnKA4UH/YeaI2kGqTXTKdaUrUTrjE+Lp6UuJSjhraIHExhLBIIeI8g/e1v3lCUcXFwySXeNIRnnunLZei9JXv5ZvU3jF4ymjFLx7B0i/d8cru0dtxz+j1c0OoCejTtcdTew2ZGYnwiifGJ1KhSozxKF5HjoDCW2LVrl9ch68UXvcE46teHBx+EoUPL/DngwqJCNhduZtOuTWzeFfxZuPmA96HL1uWvY3fxbqrEV6Fv87789rTfckGrC2ie2rxM6xKRikFhLLGnpATeeccL3rVr4Ywz4NFHvTmBq1Q5vkMGSsjdkXvQYzfLtixjxdYV7Niz47D71qxSk3op9ahbtS5pKWm0rdeW+in16Z3Rm7Oan1Uml5BFpGJTGEts+eILuP9+b2CO7t3hvffgV78Ke/cN+Rv4bu13B4Xuyq0rD+hNnBiXSPPU5mSmZtKraS8a12jsBW5K3V+Ct25KXepUraOesCIS2TA2s/7AX4B44FXn3FOl1jcD3gJqB7cZ5pwba2YZwEJgcXDT6c652yJZq0S5uXPhf/7Hm6aweXOvp/SVVx71fnBxoJjpudMZt3Qc45ePZ/a62b+sq1mlJpmpmXRs0JFL2l5ywKM36TXT1QtWRMIWsTA2s3jgReAcIBeYaWajnHMLQjZ7EPjQOfeSmbUDxgIZwXXLnXOdI1WfxIi1a+Ghh+DNN6F2bfjzn73Hk45wOfrnnT8zftl4xi0bx8TlE9m+ZzvxFk+Ppj14ot8T9M7oTas6raiXUg/TCFsiUgYi2TLuDixzzq0AMLP3gUFAaBg7YN+QRbWAnyNYj8SSnTvhmWfguee8e8T33Qd/+IM3X3ApRSVFTFszjXHLxjFu2TjmbvDGlm5cozGXt7ucAS0HcFaLs6idXLu8z0JEYkQkw7gJsCbkcy5wWqltHgW+MLO7gWrA2SHrmpvZ98AO4EHn3Delv8DMhgJDAZo1a1Z2lUvlVVwMr74KjzwCGzfC4MHwxBPepekQJYESxi0bxxs/vMHE5RPZuXcnCXEJ9GrWi6fPfpr+LftzSv1T1PIVkXLhdweuIcCbzrnnzOwM4B0z6wCsA5o55zabWVfgUzNr75w7oEuqc24EMAIgKyvr6MMMSXQbN85rAS9a5HXK+vxzr5NWiLyCPF77/jVeznmZ1dtX07B6Q4Z0GMKAVgPo17wfNatEx9jSIlK5RDKM1wKhY8SlB5eFuhnoD+Cc+9bMkoF6zrmNwJ7g8llmthxoDeREsF6prEpKvPvCTz4JbdrAp596cwYHW7XOOabnTufvOX/nw/kfsrdkL30z+vLsuc8yqM0gTbsnIr6LZBjPBFqZWXO8EB4MXF1qm5+As4A3zexkIBnIM7M0YItzrsTMWgCtgBURrFUqq23b4OqrvVbx0KHwwguQ5D0qVLC3gPfmvcffZ/6d79d/T42kGgw9dSi3d7uddmntfC5cRGS/iIWxc67YzO4CJuA9tvS6c26+mQ0Hcpxzo4DfASPN7F68zly/ds45MzsTGG5mRUAAuM05tyVStUoltXAhDBoEq1bByy/DrbcCsGTzEl6a+RJv/PAG2/ds55T6p/DSBS9xbcdrqZ7k3/jSIiKHY85Fx63WrKwsl5Ojq9gx47PP4LrrICUFPv4YevViwrIJPPftc0xcMZHEuEQua3cZd3a7k55Ne6ojlshhmNks51yW33XEOr87cIkcm0AAHnvM6y2dlQX//jcljRvxhy+H8fTUp0mvmc5jfR/j5lNvpmH1hn5XKyISFoWxVB47d8L113sdtK6/Hl55hW3s5ur3LmLcsnHcnnU7z/d/XsNLikilozCWymHZMu/+8OLF8Pzz8NvfsnDTIga9P4hV21bxyoWvMLTrUL+rFBE5LgpjqfjGj4chQyA+3pvooV8/Ri8ZzdX/upqqiVX5zw3/oVezXn5XKSJy3OL8LkDksJyDp5+G88+Hk06CmTNxffvyxDdPMPC9gbSu25qcW3IUxCJS6allLBVTQQHcfDN88AFcdRW89hoFiXDjx1fx0YKPuOaUaxh50UiqJlb1u1IRkROmMJaKp6QELr0UJk6Ep56C//kfVm5bxcXvXMy8jfP433P+l9+d8Ts9riQiUUNhLBXPk09694ZfeQWGDmXSyklc8dEVlLgSxl49lvNanud3hSIiZUr3jKVimTTJe4b4mmtwv/kNL8x4gXPeOYf61erz3W++UxCLSFRSy1gqjg0bvHGmW7dmz9/+wh2f38LrP7zORa0v4h+X/kMzKolI1FIYS8VQUuIF8fbtFE8Yx8VjrmX8svE8dOZDPNrnUeJMF3FEJHopjKVi+NOf4D//wb32Gnf99DLjl43n5Qte5tasW/2uTEQk4tTcEP99+SUMHw7XX89zbTbzyqxX+H3P3yuIRSRmqGUs/lq3Dq65Bk4+mU/vPpf7x1zLle2v5ImznvC7MhGRcqMwFv8UF3v3ifPzmfveXxgy4UbOSD+DNwe9qXvEIhJTFMbinz/+ESZPJu/vz3L2rN/SuEZjPhv8mUbVEpGYo+aH+OOLL+Dxx9lz3dWcGXiV4kAxY68eS1q1NL8rExEpd2oZS/lbuxauuYZA+3Zc3CuX5RuWM/G6ibSp18bvykREfKGWsZSv4mIYMgRXWMgfbmvF+HVf8/qg1+md0dvvykREfKMwlvL18MPwzTd8du8Antr0KY/2fpRrO17rd1UiIr5SGEv5GTcOnnySZZf15ZKEj7mu43U83Pthv6sSEfGdwljKx5o1cN115LfNpGv7bHqf1JuRF43UNIgiIqgDl5SHoiIYPJjA7kL6XVhMo7QWfHLVJ1RJqOJ3ZSIiFUJEW8Zm1t/MFpvZMjMbdoj1zcxskpl9b2Zzzez8kHUPBPdbbGaaN68ye/VVmDaN311eg5X1Exlz9RjqVK3jd1UiIhVGxFrGZhYPvAicA+QCM81slHNuQchmDwIfOudeMrN2wFggI/h+MNAeaAx8aWatnXMlkapXIqS4GPfM08zLrMFLmVuZNHgymXUy/a5KRKRCiWTLuDuwzDm3wjm3F3gfGFRqGwfsm6S2FvBz8P0g4H3n3B7n3EpgWfB4Utm8/z62ajX/r/tO3rrkbc5oeobfFYmIVDhHDWMzu8LMagTfP2hmn5jZqWEcuwmwJuRzbnBZqEeBa80sF69VfPcx7IuZDTWzHDPLycvLC6MkKVeBAO6pp1jSqAp5fbpxVYer/K5IRKRCCqdl/JBzbqeZ9QLOBl4DXiqj7x8CvOmcSwfOB94xC3+GAOfcCOdclnMuKy1NwyhWOKNHY/Pn88cz9nB79zv9rkZEpMIKJ/j23ae9ABjhnBsDJIWx31qgacjn9OCyUDcDHwI4574FkoF6Ye4rFZlz8MQTbKhfjYlZqWoVi4gcQThhvNbMXgGuAsaaWZUw95sJtDKz5maWhNcha1SpbX4CzgIws5PxwjgvuN1gM6tiZs2BVsB34ZyQVBCTJ8OMGQzvtotfZ/2G5IRkvysSEamwwulNfSXQH3jWObfNzBoB9x9tJ+dcsZndBUwA4oHXnXPzzWw4kOOcGwX8DhhpZvfideb6tXPOAfPN7ENgAVAM3Kme1JXMk0+yM7Uar3cuYH7WbX5XIyJSoR01jJ1zu8xsI9ALWIoXjkvDObhzbixex6zQZQ+HvF8A9DzMvo8Dj4fzPVLBzJoFEyfyl/Or06/d+bRIbeF3RSIiFdpRw9jMHgGygDbAG0Ai8A8OE6IiPPkke2uk8EzHfN7vpo5bIiJHE86930uAgUABgHPuZ6BGJIuSSmzRIvjkEz7oXY96DZvTv2V/vysSEanwwgnjvcH7uA7AzKpFtiSp1J55hkCVJH7X9iduz7qduPCfVBMRiVnh/J/yw2Bv6tpmdgvwJTAysmVJpbRmDbzzDl+f3ZodtapwU5eb/K5IRKRSOOI9Y/Pmt/sAaAvswLtv/LBzbmI51CaVzXPP4YA7Tl7O4A6DqZtS1++KREQqhSOGsXPOmdlY59wpgAJYDm/TJhg5ksXndWVhtRm8pY5bIiJhC+cy9Wwz6xbxSqRy++tfcYWF3H/qJrIaZ9Gtif7KiIiEK5xBP04DrjGz1Xg9qg2v0dwxopVJ5bFjB7zwApvO7cXo+G94o9sbflckIlKphBPG50W8CqncXnkFtm3jz72TqBNfh6vaaxxqEZFjcdTL1M651UBt4KLgq3ZwmQjs3g1//jN7+vTi2eIp3NT5JqomVvW7KhGRSiWc+Yz/C3gXqB98/cPM7j7yXhIz3noL1q/ngwtbUBIo4TaNQy0icszCuUx9M3Cac64AwMyeBr4FXohkYVIJFBd7g3xkZTHMfUH/lv3JrJPpd1UiIpVOOL2pjf1zGhN8b5EpRyqVjz6CFSuYfl0f1hWs545ud/hdkYhIpRROy/gNYIaZ/Tv4+WLgtciVJJWCc/DUU3DyyTxYYyYZLoMBLQf4XZWISKUUTgeuPwM3AluCrxudc89HujCp4MaOhblzyb39Wib9NIXbut5GfFy831WJiFRK4UyheDow3zk3O/i5ppmd5pybEfHqpOJ68klo1oxnTlpDle1VuPnUm/2uSESk0grnnvFLQH7I5/zgMolV33wDU6ey+567eHP+u1zV4SrqpdTzuyoRkUorrA5cwSkUAXDOBQjvXrNEqyefhLQ03slKYufendyRpY5bIiInIpwwXmFmvzWzxODrv4AVkS5MKqhNm2DcONytt/KXH0fStVFXujfp7ndVIiKVWjhhfBvQA1gL5OKNVT00kkVJBTZtGgBzT6nP/Lz53NHtDryZNkVE5Hgd9XKzc24jMLgcapHKIDsbEhP536LJpCanMriD/mqIiJyocIbDfCbYgzrRzL4yszwzu7Y8ipMKaOpU9nbpyAcrRnFj5xtJSUzxuyIRkUovnMvU5zrndgAXAquAlsD9kSxKKqjCQpg5k5zmVSgOFHN7t9v9rkhEJCqEE8b7LmVfAHzknNse7sHNrL+ZLTazZWY27BDr/8/Mfgi+lpjZtpB1JSHrRoX7nRJBOTlQVMSrKYs4L/M8WtZp6XdFIiJRIZxHlEab2SKgELjdzNKA3UfbyczigReBc/A6fs00s1HOuQX7tnHO3Ruy/d1Al5BDFDrnOod3GlIupk4F4PN6W3i6/ZU+FyMiEj3CGQ5zGF5v6iznXBGwCxgUxrG7A8uccyucc3uB94+y3xDgvTCOK37JzmZbRkM2VYOeTXv6XY2ISNQI5zI1zrktzrmS4PsC59z6MHZrAqwJ+ZwbXHYQMzsJaA78J2RxspnlmNl0M7v4MPsNDW6Tk5eXF86pyPEKBGDqVOa2rEmdqnVoXbe13xWJiESNsMK4HAwGPt4X+EEnOeeygKuB583soIlynXMjnHNZzrmstLS08qo1Ni1cCNu2Ma7hDno07aFni0VEylAkw3gt0DTkc3pw2aEMptQlaufc2uDPFcBkDryfLOUtOxuAj1LX0yO9h8/FiIhEl+MKYzNrG8ZmM4FWZtbczJLwAvegXtHBY3ueGGgAABaVSURBVKUC34YsSzWzKsH39YCewILS+0o5ys5mT93aLK8DPZoqjEVEytLxtoy/ONoGzrli4C5gArAQ+NA5N9/MhpvZwJBNBwPvh05GAZwM5JjZHGAS8FRoL2zxwdSpLD25AQnxCXRr0s3vakREosphH20ys78ebhVQO5yDO+fGAmNLLXu41OdHD7HfNOCUcL5DysHatbByJZNPy6RLwy4adUtEpIwd6TnjG4HfAXsOsW5IZMqRCin4fPGHtXPp0fRCn4sREYk+RwrjmcC8YCv1AGb2aMQqkopn6lRKkqvwbdoe7tL9YhGRMnekML6cw4y05ZxrHplypELKzubn9s0ojl+qzlsiIhFwpA5c1Z1zu8qtEqmYdu6EH37gu4xEmtZsSnrNdL8rEhGJOkcK40/3vTGzf5VDLVIRTZ8OgQD/rrtRrWIRkQg5UhiHDrHUItKFSAU1dSouLo5RdTYpjEVEIuRIYewO815iSXY221o3Y2eyBvsQEYmUI3Xg6mRmO/BayFWD7wl+ds65mhGvTvxVXAzTp/Nj30xSElPo1KCT3xWJiESlw4axcy6+PAuRCmjOHCgoYHzDfLo36U5ifKLfFYmIRKWKMmuTVETBySHerblKk0OIiESQwlgOLzub3Y0b8FPNgO4Xi4hEkMJYDs05mDqV5e0aAnB6+uk+FyQiEr0UxnJoK1fCunVMaVpC23ptqZtS1++KRESilsJYDi14v/iftX7S/WIRkQhTGMuhTZ1KSc0aTKu5Q/eLRUQiTGEsh5adzc+nZODiNNiHiEikKYzlYFu2wIIFzGyeRJ2qdWhTr43fFYmIRDWFsRxsmjeF9ad18zgj/QziTH9NREQiSf+XlYNlZ+MSE/m42k+6RC0iUg4UxnKw7Gy2tc+kMEn3i0VEyoPCWA60ezfMnMn8VrWIt3i6Ne7md0UiIlFPYSwHmjUL9u5lQsMCOjfsTLWkan5XJCIS9RTGcqDgYB9v11iuS9QiIuUkomFsZv3NbLGZLTOzYYdY/39m9kPwtcTMtoWsu8HMlgZfN0SyTgmRnc3uzJP4KalQYSwiUk4OO5/xiTKzeOBF4BwgF5hpZqOccwv2beOcuzdk+7uBLsH3dYBHgCzAAbOC+26NVL0CBAIwbRrLe7YGViuMRUTKSSRbxt2BZc65Fc65vcD7wKAjbD8EeC/4/jxgonNuSzCAJwL9I1irACxaBFu28E3TAOk102lWq5nfFYmIxIRIhnETYE3I59zgsoOY2UlAc+A/x7KvmQ01sxwzy8nLyyuTomNa8H7xe7XXqFUsIlKOKkoHrsHAx865kmPZyTk3wjmX5ZzLSktLi1BpMWTqVErq1eXrxHWaqUlEpBxFMozXAk1DPqcHlx3KYPZfoj7WfaWsZGezrlMmmAb7EBEpT5EM45lAKzNrbmZJeIE7qvRGZtYWSAW+DVk8ATjXzFLNLBU4N7hMImXdOlixgpwWyVRNqErnhp39rkhEJGZErDe1c67YzO7CC9F44HXn3HwzGw7kOOf2BfNg4H3nnAvZd4uZ/Qkv0AGGO+e2RKpWAaZOBWBUvU10a9KNxPhEnwsSEYkdEQtjAOfcWGBsqWUPl/r86GH2fR14PWLFyYGys3FVq/J+4mL+K32g39WIiMSUitKBS/yWnc32Tm0ojCvR/WIRkXKmMBbIz4cffmB+m1QAzmh6hs8FiYjEFoXxcdhbspdv13xLcaDY71LKxowZUFLCxIa7aFO3DfVS6vldkYhITFEYH4e3xzzJV9f04Pz7G/PQfx5i9bbVfpd0YrKzcWa8VXWJLlGLiPhAYXwcqo98iwe/gS/+nMd5v36MYb/JYOBb/fls0WeVs7Wcnc2e9m1YxVaFsYiIDxTGx6iwqJA2s1axqk1D+POfOS3hJN77F4y8eyI/3HYx3f+YzsOTHq48reXiYpg+nZXtGgMa7ENExA8K42P03ezP6bLOseeC8+Dee0lctgLGjiXtV/15+Gvju8c30v7uP3HdfRlc8O75Fb+1PHcu5OeT3dRRO7k2beu19bsiEZGYozA+Rj9/8hYAza74jbcgLg4GDCBuzBhs6VIS7rmPy3Nr8vUb8Mz9Exlz/8Wc/HQzHpn0CLN+nsWG/A0EXMDHMyglODnEB6lrOSP9DOJMfyVERMqbhQx8VallZWW5nJyciH/P6NNS6bmwgNRtu70gPpRdu+C993B/ewH7YQ75KQmM7FjMF5mQEIBkF0daYm3SkmqTllCLugk1qZNQg9rx1akdX41a8VWpaclUjauC9esHffuCWdmeSH4+jBgBzzxDSZUkEm5aw5/6/okHz3ywbL9HRCo0M5vlnMvyu45YpzA+Buu2ryWuSTqbenSm/RffH30H52DaNHjxRdxHH2HFx3a5OmAQ58C1b4/ddRdcdx1Uq3ac1Qdt3gwvvOC9tmyBPn2Yducges6/l6+u/4p+zfud2PFFpFJRGFcMER0OM9rMGv86FxbA7gsvDW8HM+jZE3r2xJ5/HpYvh6QkSEw88JWUxG4rYf2ezazbvYm1hRtZW7iB71dPh/c/4IEfVtPm9tth2DC46Sa4807IzDy24nNz4bnnvNbwrl0wcCA88ACcfjrj/vMQ8RZP9ybdj/0PRURETpjC+BgUfP4JAE2vuPnYd65f33sdRjKQQToZoQvPgHfbXcSpn99Cv/V1eG11Z+q/8AI8/zycfz7cfTecc87hL5cDLF4MzzwD77wDgQBcfTX8/vfQvv0vm0zLnUanhp2onlT92M9LREROmHrrhCngAqRPn8/qjNrENWpcbt97TcdrmHHLdyxpU4/GWVN46eNhuAcfhJkzoX9/OPlk75Lzjh0H7jhrFlx+ubf+n/+EW2+FZcvg7bcPCOLiQDEzcmfQI12PNImI+EVhHKZ5K6bTbWURO/qUf2h1qN+BmbfM5JKTL+GOHx7j0vY/sn3Jj15rt3Zt+O1vIT3dayl/8onXWs7Kgi+/9C5Fr17tBXZGxkHH/nHDjxQUFej5YhERHymMw7T04xEkBaDxZb/25ftrVqnJh5d/yP+d93+MXjKarLd7MufsU7xxpWfMgEGD4JVX4LLL4Mcf4emn4aef4PHHj3h5fNqaaYAG+xAR8ZN6U4fp07Obct43a6m6oxCqVInY94Rj6k9TufLjK9lSuIWXLniJX3f+tbdiwwbv8nS/fpCcfNj9dxfvZtLKSYxaPIp/LfwXSfFJrLl3DVbWj0+JSIWn3tQVgzpwhWFX0S46fJ/Lys4taOdzEAP0bNaT72/9niH/GsKNn93ItDXT+OuAv5LcoIHXsesQ8gryGLN0DJ8v+ZwJyyZQUFRAtcRqnNfyPO47/T4FsYiIjxTGYfju6/fpswUW9u/vdym/qF+tPl9c+wUPT3qYJ7KfYNa6WXx8xcc0T20OgHOOxZsXM2rxKEYtHsW0NdNwOJrUaML1na5nYJuB9MnoQ3LC4VvQIiJSPhTGYcj79F0Aml95q8+VHCg+Lp7Hz3qc09NP5/pPr+fUEafy1FlPsXTLUkYtHsXSLUsB6NKwCw/3fpiBbQbSpWEXtYJFRCoY3TMOw5eda9JhbRENN+4q+2Epy8iKrSu44qMrmL1uNknxSfRr3o+BrQdyYesLaVqrqd/liUgFpXvGFYNaxkeRu3kl3RfuZOWA02lYQYMYoEVqC6beNJWcn3Po1KATNarU8LskEREJkx5tOoq5n46g5l6oPfBKv0s5quSEZHo166UgFhGpZBTGR7Fn3CiK46DZpTf6XYqIiESpiIaxmfU3s8VmtszMhh1mmyvNbIGZzTezf4YsLzGzH4KvUZGs83ACLkDGjMWsaJ2G1a7tRwkiIhIDInbP2MzigReBc4BcYKaZjXLOLQjZphXwANDTObfVzEKHiip0znWOVH3hmDv/P3TKLeHHO870swwREYlykWwZdweWOedWOOf2Au8Dg0ptcwvwonNuK4BzbmME6zlmqz4aSRyQfjyzNImIiIQpkmHcBFgT8jk3uCxUa6C1mU01s+lmFjqqRrKZ5QSXX3yoLzCzocFtcvLy8sq2eiD5qylsqxZP3V+dW+bHFhER2cfvR5sSgFZAHyAd+NrMTnHObQNOcs6tNbMWwH/M7Efn3PLQnZ1zI4AR4D1nXJaF7dy9g45zN7C6W1tqx8eX5aFFREQOEMmW8VogdLSJ9OCyULnAKOdckXNuJbAEL5xxzq0N/lwBTAa6RLDWg8z+4i0a74SkAReV59eKiEgMimQYzwRamVlzM0sCBgOle0V/itcqxszq4V22XmFmqWZWJWR5T2AB5WjrZx8A0OKq28rza0VEJAZFLIydc8XAXcAEYCHwoXNuvpkNN7OBwc0mAJvNbAEwCbjfObcZOBnIMbM5weVPhfbCLg/1s79nVXp1qpzUojy/VkREYpDGpj6En9YupMFJ7Zh3ZR+6/nNSmRxTRKQi0tjUFYNG4DqEBR+/RJUSqHfx1X6XIiIiMUBhfAglX4xjdwI0u/Aav0sREZEYoDAupSRQQsuZK1h6ShMsJcXvckREJAYojEuZO3M0bfICFJ/dz+9SREQkRiiMS1n78esAZFx1q8+ViIhIrFAYl1J90lQ2pCaSemoPv0sREZEYoTAOsaNgC53nb2bN6e3AzO9yREQkRiiMQ/wwagS1d0PKhZf4XYqIiMQQhXGInZ9/TIlByys1BKaIiJQfhXGIJtPmsTQzlaR6DfwuRUREYojCOGjl8lmc8tMedvQ53e9SREQkxiiMg5Z9+DLxDhpedoPfpYiISIxRGAfZFxPZkWw0PetSv0sREZEYozAGikuKOHn2Tyw9NQNLTPS7HBERiTEKY2DupPdpssPBuef6XYqIiMQghTGw8ZN3AMgccqfPlYiISCxSGAO1v/6OVQ2Tqd36FL9LERGRGBTzYbx1y890WryddT06+V2KiIjEqJgPY9u+g1V9O9Pg6lv8LkVERGJUgt8F+K1287bU/uJ7v8sQEZEYFvMtYxEREb8pjEVERHymMBYREfFZRMPYzPqb2WIzW2Zmww6zzZVmtsDM5pvZP0OW32BmS4MvDRgtIiJRK2IduMwsHngROAfIBWaa2Sjn3IKQbVoBDwA9nXNbzax+cHkd4BEgC3DArOC+WyNVr4iIiF8i2TLuDixzzq1wzu0F3gcGldrmFuDFfSHrnNsYXH4eMNE5tyW4biLQP4K1ioiI+CaSYdwEWBPyOTe4LFRroLWZTTWz6WbW/xj2xcyGmlmOmeXk5eWVYekiIiLlx+8OXAlAK6APMAQYaWa1w93ZOTfCOZflnMtKS0uLUIkiIiKRFclBP9YCTUM+pweXhcoFZjjnioCVZrYEL5zX4gV06L6Tj/Rls2bN2mRmq4Mf6wGbjrvyyi2Wzx1i+/xj+dwhts//RM79pLIsRI6POecic2CzBGAJcBZeuM4ErnbOzQ/Zpj8wxDl3g5nVA74HOhPstAWcGtx0NtDVObclzO/Occ5lldnJVCKxfO4Q2+cfy+cOsX3+sXzu0SJiLWPnXLGZ3QVMAOKB151z881sOJDjnBsVXHeumS0ASoD7nXObAczsT3gBDjA83CAWERGpbCLWMvZTLP8rMZbPHWL7/GP53CG2zz+Wzz1a+N2BK1JG+F2Aj2L53CG2zz+Wzx1i+/xj+dyjQlS2jEVERCqTaG0Zi4iIVBoKYxEREZ9FVRiHMzFFNDOzVWb2o5n9YGY5ftcTaWb2upltNLN5IcvqmNnE4AQjE80s1c8aI+Uw5/6oma0N/v5/MLPz/awxUsysqZlNCplg5r+Cy6P+d3+Ec4+J3300i5p7xsGJKZYQMjEF3jPMC464YxQxs1VAlnMuJgY+MLMzgXzgbedch+CyZ4Atzrmngv8gS3XO/d7POiPhMOf+KJDvnHvWz9oizcwaAY2cc7PNrAbemAQXA78myn/3Rzj3K4mB3300i6aWcTgTU0gUcc59DZR+/nwQ8Fbw/Vt4/6OKOoc595jgnFvnnJsdfL8TWIg3dn3U/+6PcO5SyUVTGIc1uUSUc8AXZjbLzIb6XYxPGjjn1gXfrwca+FmMD+4ys7nBy9hRd5m2NDPLALoAM4ix332pc4cY+91Hm2gKY4FezrlTgQHAncFLmTHLefdgouM+THheAjLxhpRdBzznbzmRZWbVgX8B9zjndoSui/bf/SHOPaZ+99EomsI4nIkpoppzbm3w50bg33iX7mPNhuB9tX331zYeZfuo4Zzb4Jwrcc4FgJFE8e/fzBLxwuhd59wnwcUx8bs/1LnH0u8+WkVTGM8EWplZczNLAgYDo3yuqdyYWbVghw7MrBpwLjDvyHtFpVHADcH3NwCf+VhLudoXREGXEKW/fzMz4DVgoXPuzyGrov53f7hzj5XffTSLmt7UAMHu/M+zf2KKx30uqdyYWQu81jB4E4D8M9rP38zew5tqsx6wAXgE+BT4EGgGrAaujMZJRg5z7n3YP+vZKuDWkHuoUcPMegHfAD8CgeDi/4d37zSqf/dHOPchxMDvPppFVRiLiIhURtF0mVpERKRSUhiLiIj4TGEsIiLiM4WxiIiIzxTGIiIiPlMYS6VmZs7Mngv5/N/BCRPK4thvmtnlZXGso3zPFWa20MwmlVqeYWaFITPx/GBm15fh9/Yxs9FldTwROX4JfhcgcoL2AJea2ZMVabYqM0twzhWHufnNwC3OuexDrFvunOtchqWJSAWklrFUdsXACODe0itKt2zNLD/4s4+ZTTGzz8xshZk9ZWbXmNl3wfmgM0MOc7aZ5ZjZEjO7MLh/vJn9r5nNDA7Mf2vIcb8xs1HAQVN3mtmQ4PHnmdnTwWUPA72A18zsf8M9aTPLN7P/C85p+5WZpQWXdzaz6cG6/r1vwgAza2lmX5rZHDObHXKO1c3sYzNbZGbvBkd4EpFypjCWaPAicI2Z1TqGfToBtwEnA9cBrZ1z3YFXgbtDtsvAG+f3AuBlM0vGa8lud851A7oBt5hZ8+D2pwL/5ZxrHfplZtYYeBrohzdSUjczu9g5NxzIAa5xzt1/iDozS12m/lVweTUgxznXHpiCNwIXwNvA751zHfFGadq3/F3gRedcJ6AH3mQC4M36cw/QDmgB9Azjz05EypguU0ul55zbYWZvA78FCsPcbea+4QLNbDnwRXD5j0DfkO0+DA6+v9TMVgBt8cb97hjS6q4FtAL2At8551Ye4vu6AZOdc3nB73wXOBNv+M4jOdxl6gDwQfD9P4BPgv8Yqe2cmxJc/hbwUXDM8ibOuX8DOOd2B2sgWG9u8PMPeP/4ONTlchGJIIWxRIvngdnAGyHLigle/TGzOCApZN2ekPeBkM8BDvzvovR4sQ4w4G7n3ITQFWbWByg4vvJP2PGOaxv651CC/p8g4gtdppaoEJwQ4EO8S8j7rAK6Bt8PBBKP49BXmFlc8B5rC2AxMAG4PTiVHWbWOjhT1pF8B/Q2s3pmFo83sP+Uo+xzJHHAvpb51UC2c247sDXkUvZ1wBTn3E4g18wuDtZbxcxSTuC7RaSM6V/BEk2eA+4K+TwS+MzM5gDjOb5W6094QVoTuM05t9vMXsW7nDs72OEpD7j4SAdxzq0zs2HAJLyW9RjnXDhT/GUGLx/v87pz7q9459LdzB7Em7f3quD6G/DubacAK4Abg8uvA14xs+FAEXBFGN8tIuVEszaJVEJmlu+cq+53HSJSNnSZWkRExGdqGYuIiPhMLWMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERn/1/Iu0nn6LxhW8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}