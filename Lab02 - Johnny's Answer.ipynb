{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnnyPeng123/NLP-USYD/blob/master/Lab02%20-%20Johnny's%20Answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCHPkKbuhPF6",
        "colab_type": "text"
      },
      "source": [
        "# Lab 02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV7vMHSahdnf",
        "colab_type": "text"
      },
      "source": [
        "## Google Drive Access Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTSQtnPkfyzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0isQ539cf_nI",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNyhgK5QTOuD",
        "colab_type": "code",
        "outputId": "dc9b66c6-871e-45bd-8963-f9de2fa2624e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pprint\n",
        "import re\n",
        "from lxml import etree\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewAbjQzThnT5",
        "colab_type": "text"
      },
      "source": [
        "### Downloading TED Scripts from Google Drive \n",
        "Click on left side \"Files\" tab and see the file is downloaded successfully."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVk7tjwvhl-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id = '1B47OiEiG2Lo1jUY6hy_zMmHBxfKQuJ8-'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('ted_en-20160408.xml')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIPpEvI4kqMV",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYmEQgB7XoDE",
        "colab_type": "code",
        "outputId": "14216acf-ea09-40ca-f35a-997523e06251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "targetXML=open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "\n",
        "# Getting contents of <content> tag from the xml file\n",
        "target_text = etree.parse(targetXML)\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "# Removing \"Sound-effect labels\" using regular expression (i.e. (Audio), (Laughter))\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "# Tokenising the sentence to process it by using NLTK library\n",
        "sent_text=sent_tokenize(content_text)\n",
        "\n",
        "# Removing punctuations and changing all characters to lower case\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "     normalized_text.append(tokens)\n",
        "\n",
        "# Tokenising each sentence to process individual word\n",
        "sentences=[]\n",
        "sentences=[word_tokenize(sentence) for sentence in normalized_text]\n",
        "\n",
        "# Prints only 10 (tokenised) sentences\n",
        "print(sentences[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new'], ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation'], ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing'], ['consider', 'facit'], ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them'], ['facit', 'was', 'a', 'fantastic', 'company'], ['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world'], ['everybody', 'used', 'them'], ['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along'], ['they', 'continued', 'doing', 'exactly', 'the', 'same']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CojV1MbhkQxK",
        "colab_type": "text"
      },
      "source": [
        "### Word2Vec - Continuous Bag-Of-Words (CBOW)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW1iEee3lZC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wv_cbow_model = Word2Vec(sentences=sentences, size=100, window=5, min_count=5, workers=4, sg=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FKp3X7pkRm6",
        "colab_type": "code",
        "outputId": "2925c0e7-b611-4f89-9a88-1f58311784eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "similar_words=wv_cbow_model.wv.most_similar(\"man\")\n",
        "pprint.pprint(similar_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('woman', 0.8512791991233826),\n",
            " ('guy', 0.8174343109130859),\n",
            " ('lady', 0.7742480635643005),\n",
            " ('gentleman', 0.7678461670875549),\n",
            " ('boy', 0.7588591575622559),\n",
            " ('girl', 0.7372721433639526),\n",
            " ('soldier', 0.7263712882995605),\n",
            " ('kid', 0.699205219745636),\n",
            " ('photographer', 0.6811155676841736),\n",
            " ('poet', 0.6806650161743164)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsFHg0znlPSf",
        "colab_type": "text"
      },
      "source": [
        "### Word2Vec - Skip Gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k16AowhCWUXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wv_sg_model = Word2Vec(sentences=sentences, size=100, window=5, min_count=5, workers=4, sg=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8UiVfr2cBtA",
        "colab_type": "code",
        "outputId": "184223a4-cc31-4f14-f0c1-609330db7657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "similar_words=wv_sg_model.wv.most_similar(\"man\")\n",
        "pprint.pprint(similar_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('woman', 0.7736088633537292),\n",
            " ('guy', 0.741553783416748),\n",
            " ('soldier', 0.7228139638900757),\n",
            " ('rabbi', 0.7062848806381226),\n",
            " ('pianist', 0.6645767092704773),\n",
            " ('boy', 0.6637154221534729),\n",
            " ('michelangelo', 0.6623799800872803),\n",
            " ('adage', 0.6590092182159424),\n",
            " ('gentleman', 0.6551796793937683),\n",
            " ('pope', 0.6545050144195557)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfF7YqvpppbG",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec vs FastText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8IV7D6VAEcr",
        "colab_type": "text"
      },
      "source": [
        "Let's try to find out the difference between Word2Vec and FastText\n",
        "\n",
        "Word2Vec - Skipgram cannot find similar word \"electrofishing\" as \"electrofishing\" is not in the vocabulary - so you can see the error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS9c2uWWquWG",
        "colab_type": "code",
        "outputId": "20b71492-8831-4ef2-f4a4-44a4a7fc5399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "similar_words=wv_sg_model.wv.most_similar(\"electrofishing\")\n",
        "pprint.pprint(similar_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a2f7ec57b31e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimilar_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwv_sg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"electrofishing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'electrofishing' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TpkScI8sA9G",
        "colab_type": "text"
      },
      "source": [
        "### FastText - Skip Gram\n",
        "\n",
        "You can find that FastText works extremely well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAqOR1Vqps6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqkvyiUw_DRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft_sg_model = FastText(sentences, size=100, window=5, min_count=5, workers=4, sg=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv26QObJriB7",
        "colab_type": "code",
        "outputId": "4bd99bd3-e14f-40d2-b305-1e10e4c3f2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "result=ft_sg_model.wv.most_similar(\"electrofishing\")\n",
        "pprint.pprint(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('electrolux', 0.7936742305755615),\n",
            " ('airbus', 0.7896213531494141),\n",
            " ('electrolyte', 0.7837408781051636),\n",
            " ('electro', 0.7774487733840942),\n",
            " ('railroads', 0.7706649899482727),\n",
            " ('electric', 0.7632849216461182),\n",
            " ('gastric', 0.7626646757125854),\n",
            " ('railroad', 0.7593973278999329),\n",
            " ('electrogram', 0.7557892799377441),\n",
            " ('fukushima', 0.748328685760498)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0x2aQpfsFSx",
        "colab_type": "text"
      },
      "source": [
        "### FastText - Continuous Bag-Of-Words (CBOW)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUBqvqpc2sbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft_cbow_model = FastText(sentences, size=100, window=5, min_count=5, workers=4, sg=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUj1RUzM2nLA",
        "colab_type": "code",
        "outputId": "f0219e10-bdab-41ed-9e98-6a11ad74b3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "result=ft_cbow_model.wv.most_similar(\"electrofishing\")\n",
        "pprint.pprint(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('electric', 0.9211210608482361),\n",
            " ('electro', 0.9065508842468262),\n",
            " ('electrolux', 0.8940919041633606),\n",
            " ('electron', 0.8820742964744568),\n",
            " ('electronic', 0.8793923258781433),\n",
            " ('electrical', 0.8763437271118164),\n",
            " ('electrode', 0.8752334117889404),\n",
            " ('electroshock', 0.875156044960022),\n",
            " ('electrolyte', 0.874466061592102),\n",
            " ('electromagnet', 0.8660199642181396)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hjmOhmRi7Ov",
        "colab_type": "text"
      },
      "source": [
        "## King + Woman - Man = ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw7b9OSwjGm0",
        "colab_type": "text"
      },
      "source": [
        "Try both CBOW and Skip Gram model to calculate \"King - Man + Woman = ?\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovTXjSdgrw36",
        "colab_type": "code",
        "outputId": "f6727d97-d7dc-4089-db60-ccefc54b92ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result = wv_cbow_model.wv.most_similar(positive=['king' , 'woman'], negative=['man'], topn=1)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('president', 0.7961100339889526)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUtbE2jwq1to",
        "colab_type": "code",
        "outputId": "a911ad6a-1f84-4b32-f21c-32a538c0f1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result = wv_sg_model.wv.most_similar(positive=['king' , 'woman'], negative=['man'], topn=1)\n",
        "print(result)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('luther', 0.6692537069320679)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PWf2I4_WZpG",
        "colab_type": "code",
        "outputId": "782fa5b8-6513-4b42-fe98-a44158e08e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result = ft_cbow_model.wv.most_similar(positive=['king' , 'woman'], negative=['man'], topn=1)\n",
        "print(result)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('kidding', 0.8965729475021362)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9x51rRhWZrx",
        "colab_type": "code",
        "outputId": "22423608-9f7f-45b3-8565-71993c3c184c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result = ft_sg_model.wv.most_similar(positive=['king' , 'woman'], negative=['man'], topn=1)\n",
        "print(result)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('hawking', 0.6642031073570251)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpAd8t-wjTMA",
        "colab_type": "text"
      },
      "source": [
        "This is not what we expected...Probably not enough data to answer as \"Queen\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMY5w8F7rElp",
        "colab_type": "text"
      },
      "source": [
        "### Google's Pretrained Word2Vec (Google News)\n",
        "[Pretrained Model Source](https://code.google.com/archive/p/word2vec/)\n",
        "\n",
        "\n",
        "Let's  try with bigger sized data (Google has already trained Word2Vec with Google News data)\n",
        "\n",
        "**Beware, this file is big (3.39GB) - long waiting!! I recommend not to train during the lab**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teQvZDSirVVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Beware, this file is big (3.39GB) - long waiting!!\n",
        "id2 = '1cOEYOQRd1VXi7ROShhqZbioCcePvgnR5'\n",
        "downloaded = drive.CreateFile({'id':id2}) \n",
        "downloaded.GetContentFile('GoogleNews-vectors-negative300.bin')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64e_sRJ1rhUa",
        "colab_type": "code",
        "outputId": "5d7e011d-7c31-4812-d66d-b63cb58ecac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "filename = 'GoogleNews-vectors-negative300.bin'\n",
        "gn_wv_model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvMQp2-Tr3zl",
        "colab_type": "code",
        "outputId": "c058134f-5ace-40c2-c5f4-bba79e5f2861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result = gn_wv_model.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('queen', 0.7118192911148071)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqLruu6247Ze",
        "colab_type": "text"
      },
      "source": [
        "# Play with Colab Form Fields \n",
        "**The Form** supports multiple types of fields, including **input fields**, **dropdown menus**.\n",
        "\n",
        "You can edit this section by double-clicking it. \n",
        "\n",
        "Let's get familiar by changing the value in each input field (on the right) and checking the changes in the code (on the left) - vice versa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBNvQmee5QIG",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "9933b878-56f5-465c-f61f-0b0135ec0490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#@title Example form fields\n",
        "#@markdown please put description\n",
        "\n",
        "string = 'examples'  #@param {type: \"string\"}\n",
        "slider_value = 119  #@param {type: \"slider\", min: 100, max: 200}\n",
        "number = 102  #@param {type: \"number\"}\n",
        "date = '2020-01-05'  #@param {type: \"date\"}\n",
        "pick_me = \"monday\"  #@param ['monday', 'tuesday', 'wednesday', 'thursday']\n",
        "select_or_input = \"apples\" #@param [\"apples\", \"bananas\", \"oranges\"] {allow-input: true}\n",
        "\n",
        "\n",
        "#print the output\n",
        "print(\"string is\",string)\n",
        "print('slider_value',slider_value)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "string is examples\n",
            "slider_value 119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DupJY3rOcozM",
        "colab_type": "text"
      },
      "source": [
        "# Exercise\n",
        "In this exercise, you need to implement a **'Word Algebra Calculator'  interface** using Word2Vec and FastText trained by the provided TED Scripts. The interface can be built by Colab Form Fields we just learned above.\n",
        "\n",
        "What the users can do through the interface are:\n",
        "\n",
        "\n",
        "1.   Input the word formula in the text field, e.g. King - Man + Woman\n",
        "2.   Select the word embedding model from dropdown menu, either Word2Vec or FastText\n",
        "3.   Select the training architecture from dropdown menu, either CBOW or Skip Gram\n",
        "4.   Get(print out) the resulted word of the input formula by running the form (same to running the code section)\n",
        "\n",
        "\n",
        "\n",
        "Note: \n",
        "1. Please **do not** put the training process into your form section.\n",
        "2. Please make your interface 'user-friendly' and instructional for users to use, e.g. by adding proper explaination or guide\n",
        "3. We will use formula like \"Word1 + Word2 + Word3 - Word4\" to test your interface, the number of the words and the sign between each two words can vary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-EzW_8NSLnL",
        "colab_type": "text"
      },
      "source": [
        "#Start your excercise from here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6-5SLhlSZgX",
        "colab_type": "text"
      },
      "source": [
        "## 1.The TED scripts\n",
        "The code is already provided in the above sections 'Google Drive Access Setup' and 'Word2Vec'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3mPDQvoIPao",
        "colab_type": "code",
        "outputId": "04d5fde1-375d-464a-febc-796c95d1ee65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import pprint\n",
        "import re\n",
        "from lxml import etree\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1B47OiEiG2Lo1jUY6hy_zMmHBxfKQuJ8-'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('ted_en-20160408.xml') \n",
        "\n",
        "targetXML=open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "\n",
        "# Getting contents of <content> tag from the xml file\n",
        "target_text = etree.parse(targetXML)\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "# Removing \"Sound-effect labels\" using regular expression (i.e. (Audio), (Laughter))\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "# Tokenising the sentence to process it by using NLTK library\n",
        "sent_text=sent_tokenize(content_text)\n",
        "\n",
        "# Removing punctuations and changing all characters to lower case\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "     normalized_text.append(tokens)\n",
        "\n",
        "# Tokenising each sentence to process individual word\n",
        "sentences=[]\n",
        "sentences=[word_tokenize(sentence) for sentence in normalized_text]\n",
        "\n",
        "# Prints only 10 (tokenised) sentences\n",
        "print(sentences[:10])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new'], ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation'], ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing'], ['consider', 'facit'], ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them'], ['facit', 'was', 'a', 'fantastic', 'company'], ['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world'], ['everybody', 'used', 'them'], ['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along'], ['they', 'continued', 'doing', 'exactly', 'the', 'same']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur90NpMBStBn",
        "colab_type": "text"
      },
      "source": [
        "## 2.Build your word embedding models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMpJYtCcHytp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Please generate four different types of word embedding models with TED data\n",
        "## The parameter for all four models:  size=100, window=5, min_count=5, workers=4.\n",
        "\n",
        "def get_4_models(sentences):\n",
        "\n",
        "    #put your model training code here\n",
        "    wv_cbow_model = Word2Vec(sentences=sentences, size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "    wv_sg_model = Word2Vec(sentences=sentences, size=100, window=5, min_count=5, workers=4, sg=1)\n",
        "    ft_cbow_model = FastText(sentences, size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "    ft_sg_model = FastText(sentences, size=100, window=5, min_count=5, workers=4, sg=1)\n",
        "\n",
        "    return wv_cbow_model, wv_sg_model, ft_cbow_model, ft_sg_model\n",
        "wv_cbow_model, wv_sg_model, ft_cbow_model, ft_sg_model = get_4_models(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGrBhxGXTDzF",
        "colab_type": "text"
      },
      "source": [
        "##3.Build your Interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdEQ0ATwTfUU",
        "colab_type": "text"
      },
      "source": [
        "You can edit the following form elements to build your interface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHYSXY5DcjPh",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53a6c414-9ab4-474f-ff09-fde3e50dc841"
      },
      "source": [
        "#@title Word Algebra Calculator \n",
        "\n",
        "#@markdown Please select the model and formula to calculate the word algebra\n",
        "\n",
        "# Get the input\n",
        "Formula = 'University + Students' #@param {type: \"string\"}\n",
        "Formula = Formula.lower()\n",
        "Model = 'Word2Vec' #@param ['Word2Vec', 'FastText']\n",
        "Architecture = \"CBOW\" #@param [\"CBOW\", \"Skip Gram\"]\n",
        "\n",
        "## 1.choose the corresponding model \n",
        "## 2.processing the formula to extract the postive and negative word list\n",
        "## Tip: string.split() can split the string into a list of words seperated by white space \n",
        "## 3.calculate the formula for an similar word using the selected model\n",
        "\n",
        "## 5.print out the most similar word after \n",
        "## we run the code cell \n",
        "Formula = Formula.split()\n",
        "\n",
        "negative_words = []\n",
        "postive_words = []\n",
        "\n",
        "for i in range(int(((len(Formula)-1)/2)+1)):\n",
        "  if i == 0:\n",
        "    postive_words.append(Formula[i])\n",
        "  elif Formula[i*2-1] == '-':\n",
        "    negative_words.append(Formula[i*2])\n",
        "  else:\n",
        "    postive_words.append(Formula[i*2])\n",
        "\n",
        "if Model == 'Word2Vec' and Architecture == \"Skip Gram\":\n",
        "  result = wv_sg_model.wv.most_similar(positive=postive_words, negative=negative_words, topn=1)\n",
        "if Model == 'Word2Vec' and Architecture == \"CBOW\":\n",
        "  result = wv_cbow_model.wv.most_similar(positive=postive_words, negative=negative_words, topn=1)\n",
        "if Model == 'FastText' and Architecture == \"Skip Gram\":\n",
        "  result = ft_sg_model.wv.most_similar(positive=postive_words, negative=negative_words, topn=1)\n",
        "if Model == 'FastText' and Architecture == \"CBOW\":\n",
        "  result = ft_cbow_model.wv.most_similar(positive=postive_words, negative=negative_words, topn=1)\n",
        "\n",
        "print(\"The result is: \",result)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The result is:  [('harvard', 0.8168218731880188)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPuNGP-7V88f",
        "colab_type": "text"
      },
      "source": [
        "##Expected Example\n",
        "\n",
        "\n",
        "![alt text](https://usydnlpgroup.files.wordpress.com/2020/03/image-3-1.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://usydnlpgroup.files.wordpress.com/2020/03/image-4-1.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGWS_bHuZK1D",
        "colab_type": "text"
      },
      "source": [
        "#Extensions - Learn more details!\n",
        "\n",
        "##Word2Vec with Tensorflow - official\n",
        "If you want to implement Word2Vec with Tensorflow, here is a [sample code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py) by [tensorflow](https://github.com/tensorflow).\n",
        "\n",
        "##Word2Vec with Pytorch\n",
        "Pytorch version can be found [here](https://rguigoures.github.io/word2vec_pytorch/) but this is not official\n"
      ]
    }
  ]
}